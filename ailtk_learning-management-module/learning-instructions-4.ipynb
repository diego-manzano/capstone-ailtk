{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Accessing cloud-based LLM models and implementing RAG (Development)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Links to study:\n",
    "\n",
    "[1] <a href=\"https://www.ibm.com/topics/fine-tuning\">Fine-tuning</a>\n",
    "\n",
    "[2] <a href=\"https://www.youtube.com/watch?v=8-lz_h9uuOU\">Video - Tuning Google Gemini instances with Google AI Studio</a>\n",
    "\n",
    "[3] <a href=\"https://developers.googleblog.com/en/tune-gemini-pro-in-google-ai-studio-or-with-the-gemini-api/\">Tuning Google Gemini instances with Google AI Studio - Article</a>\n",
    "\n",
    "[4] <a href=\"https://aws.amazon.com/what-is/prompt-engineering/\">Amazon: Prompt Engineering</a>\n",
    "\n",
    "[5] <a href=\"https://cloud.google.com/discover/what-is-prompt-engineering?hl=en\">Google Prompt Engineering: Overview and Guide</a>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Practice Learning\n",
    "\n",
    "Try answering [Practice Learning Activity 4](learning-activities/practice-learning-activity-4.ipynb) yourself here before proceeding below.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've finally started working with large-language-models (LLMs). In the following chapter, we're going to see how we can evaluate the models's performance using the Google Gemini API and Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Next: Learning Instructions 5](../ltk_learning-instructions/learning-instructions-5.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
