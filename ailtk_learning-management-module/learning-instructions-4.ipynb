{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Accessing cloud-based LLM models and implementing RAG (Development)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Links to study:\n",
    "\n",
    "[1] <a href=\"https://ai.google/discover/generativeai/\">Generative AI Overview by Google AI</a>\n",
    "\n",
    "[2] <a href=\"https://www.youtube.com/watch?v=G2fqAlgmoPo\">Video - Introduction to Generative AI</a>\n",
    "\n",
    "[3] <a href=\"https://ai.google.dev/gemini-api/docs/prompting-intro\">Introduction to prompt design by Google AI for Developers</a>\n",
    "\n",
    "[4] <a href=\"https://aws.amazon.com/what-is/prompt-engineering/\">Amazon: Prompt Engineering by AWS</a>\n",
    "\n",
    "[5] <a href=\"https://cloud.google.com/discover/what-is-prompt-engineering?hl=en\">Prompt Engineering: Overview and Guide by Google </a>\n",
    "\n",
    "[6] <a href=\"https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/\"> What is RAG? (Nvidia) </a>\n",
    "\n",
    "[7] <a href=\" https://aws.amazon.com/what-is/retrieval-augmented-generation/\"> RAG by Amazon Web Services </a>\n",
    "\n",
    "[8] <a href=\"https://learnbybuilding.ai/tutorials/rag-from-scratch#working-through-an-example-the-simplest-rag-system\">A simple RAG implementation</a>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing cloud-based LLM models involves leveraging external platforms or services that provide pre-trained large language models via APIs. These models, hosted in the cloud, offer scalable solutions for natural language processing tasks without the need for extensive on-premise infrastructure. \n",
    "\n",
    "Developers interact with these models by sending input data to the API and receiving generated responses, enabling applications to tap into the power of sophisticated AI without needing to train models from scratch. Furthermore, implementing RAG (Retrieval-Augmented Generation) combines the capabilities of LLMs with external data retrieval and allows models to access and incorporate real-time information from external databases, knowledge bases, or documents to enhance response accuracy and relevance. \n",
    "\n",
    "This approach improves the quality of generated responses by allowing the model to refer to relevant data and provides more informed and contextually appropriate outputs for better user interaction and decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Practice Learning\n",
    "\n",
    "Try answering [Practice Learning Activity 4](learning-activities/practice-learning-activity-4.ipynb) yourself here before proceeding below.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've finally started working with large-language-models (LLMs). In the following chapter, we're going to see how we can evaluate the models's performance using the Google Gemini API and Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Next: Learning Instructions 5](../ltk_learning-instructions/learning-instructions-5.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
