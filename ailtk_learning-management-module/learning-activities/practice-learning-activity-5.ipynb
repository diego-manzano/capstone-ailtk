{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Learning Activity 5 (Evaluate models on use cases and for safety)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Case Scenario:** \n",
    ">\n",
    "> CoffeePro’s virtual coffee concierge has reached its final stages of development. With the model fine-tuned and equipped with Retrieval-Augmented Generation (RAG) capabilities, it’s time to ensure that the AI system performs effectively across various real-world scenarios while adhering to safety standards.\n",
    ">\n",
    "> As the AI developer, your role is to evaluate the model’s functionality and robustness against multiple criteria. This includes assessing the accuracy of coffee recommendations, the reliability of brewing advice, and the system’s ability to handle edge cases, such as incomplete or contradictory user inputs. Furthermore, the evaluation must ensure that the virtual agent aligns with ethical AI guidelines, avoiding biased recommendations or potentially unsafe brewing instructions.\n",
    ">\n",
    "> Management has also emphasized that the virtual concierge should operate within brand guidelines, maintaining a professional and friendly tone to reinforce customer trust and satisfaction.\n",
    "> \n",
    "> Your Tasks:\n",
    ">\n",
    "> (a) Performance Testing:\n",
    "> Test the virtual agent on a range of user inputs to ensure it delivers accurate and personalized coffee recommendations. Simulate scenarios for both beginner coffee drinkers and enthusiasts with advanced preferences.\n",
    ">\n",
    "> (b) Safety and Ethical Review:\n",
    "> Evaluate the model for any outputs that could be misleading, unsafe, or biased. For example, verify that brewing instructions are accurate and practical, and recommendations are inclusive of a diverse range of preferences.\n",
    ">\n",
    "> By the end of this activity, you will have a clear understanding of how to use Python libraries and sample use cases to test model safety and reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Pre-requisites: \n",
    "- Load your virtual agent. Click here to open\n",
    "    - Run the code cell below to import the Google GenerativeAI Python module and initialize our LLM instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab0dd5a7ae7462e85e2356b8054b3a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='\\n# Import Google GenerativeAI Python module\\nimport google.generativeai as genai\\n\\n# Define …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code Segment\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Define the Python code you want users to copy\n",
    "code_snippet = \"\"\"\n",
    "# Import Google GenerativeAI Python module\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Define Gemini API key\n",
    "genai.configure(api_key=\"YOUR_GEMINI_API_KEY\")\n",
    "\n",
    "# Create the model\n",
    "generation_config = {\n",
    "  \"temperature\": 1,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 40,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "# Specify model name and define system instruction\n",
    "model = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-pro\",\n",
    "  generation_config=generation_config,\n",
    "  system_instruction=\"You are to serve as an AI virtual agent-coffee concierge for a company known as CoffeePro.\\n    As a leading coffee retailer CoffeePro, aims to enhance their service of of selling wide\\n    arrays coffee beans and blends from all around the world by providing personalized recommendations. \\n\\n    Given a user's preferences, such as:\\n    * Drinking preference: Black or with milk/sugar\\n    * Roast level: Light, medium, or dark\\n    * Brew method: Espresso, pour over, cold brew, or French press\\n    * Flavor profile: Fruity, nutty, chocolatey, or floral\\n\\n    You should:\\n    1. Analyze the user's preferences and access your knowledge base of coffee beans to identify suitable options.\\n    2. Provide detailed descriptions of recommended coffees, including their origin, flavor profile, and ideal brewing methods, based on the information provided from you in the injected prompts.\\n    3. Offer personalized advice on brewing techniques, water temperature, and grind size to optimize the coffee experience.\\n    4. Share interesting coffee facts and trivia to engage the user and foster a deeper appreciation for coffee.\\n    5. Provide recommendations for food pairings that complement the coffee's flavor profile.\\n    6. Answer questions about coffee history, roasting processes, and brewing techniques in a clear and informative manner.\\n    7. Maintain a friendly and conversational tone to create a positive user experience. \",\n",
    ")\n",
    "\n",
    "# Acceptable past chat for reference\n",
    "chat_session = model.start_chat(\n",
    "  history=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"parts\": [\n",
    "        \"Hello\",\n",
    "      ],\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"model\",\n",
    "      \"parts\": [\n",
    "        \"Hello there! Welcome to CoffeePro, your personal coffee concierge. I'm here to help you discover your perfect cup.  Tell me a little about your coffee preferences so I can recommend something you'll love.  Do you typically drink your coffee black, or with milk and/or sugar? What roast levels do you prefer? What's your go-to brewing method? And are there any particular flavor profiles you enjoy (fruity, nutty, chocolatey, floral, etc.)?  The more information you share, the better I can tailor my recommendations.\\n\",\n",
    "      ],\n",
    "    },\n",
    "  ]\n",
    ")\n",
    "\"\"\"\n",
    "# Create a TextArea widget to display the code\n",
    "code_widget = widgets.Textarea(\n",
    "    value=code_snippet,\n",
    "    placeholder='Python code',\n",
    "    description='Code:',\n",
    "    disabled=True,  # Disable editing to make it read-only\n",
    "    layout=widgets.Layout(width='1400px', height='250px')  # Adjust size as needed\n",
    ")\n",
    "\n",
    "# Display the widget\n",
    "display(code_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load your virtual agent (cont.)\n",
    "    - Initialize RAG by running the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe6ead10442401cabfb2b1e7533859f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='\\nimport pandas as pd\\n\\n# Load the Excel file\\ndf = pd.read_excel(\"solution-practice-learning…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the Python code you want users to copy\n",
    "code_snippet = \"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(\"solution-practice-learning-activity-3/ailtk-fine-tuning-data.xls\")\n",
    "\n",
    "# Combine relevant columns into a single document per row\n",
    "# Example: Assume 'Title' and 'Content' columns\n",
    "corpus = df.apply(lambda row: f\"{row['input']}. {row['output']}\", axis=1).tolist()\n",
    "\n",
    "def jaccard_similarity(query, document):\n",
    "    query = query.lower().split(\" \")\n",
    "    document = document.lower().split(\" \")\n",
    "    intersection = set(query).intersection(set(document))\n",
    "    union = set(query).union(set(document))\n",
    "    return len(intersection)/len(union)\n",
    "\n",
    "def return_response(query, corpus, top_n=5):\n",
    "    similarities = []\n",
    "    \n",
    "    # Calculate similarity for each document in the corpus\n",
    "    for doc in corpus:\n",
    "        similarity = jaccard_similarity(query, doc)\n",
    "        similarities.append(similarity)\n",
    "    \n",
    "    # Get the indices of the top_n most similar documents\n",
    "    top_n_indices = sorted(range(len(similarities)), key=lambda i: similarities[i], reverse=True)[:top_n]\n",
    "    \n",
    "    # Return the top_n most similar documents\n",
    "    top_n_documents = [corpus[i] for i in top_n_indices]\n",
    "    \n",
    "    return top_n_documents\n",
    "\"\"\"\n",
    "# Create a TextArea widget to display the code\n",
    "code_widget = widgets.Textarea(\n",
    "    value=code_snippet,\n",
    "    placeholder='Python code',\n",
    "    description='Code:',\n",
    "    disabled=True,  # Disable editing to make it read-only\n",
    "    layout=widgets.Layout(width='1400px', height='250px')  # Adjust size as needed\n",
    ")\n",
    "\n",
    "# Display the widget\n",
    "display(code_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load your virtual agent (cont.)\n",
    "    - Run the code cell below to Define a function to find documents similar to the user's input, provide your LLM with an injected prompt, and receive a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1447083365c143da9c4ffe5155fe2d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='\\n# Define a function to find documents similar to the user\\'s input, \\n# Provide LLM with an …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the Python code you want users to copy\n",
    "code_snippet = \"\"\"\n",
    "# Define a function to find documents similar to the user's input, \n",
    "# Provide LLM with an injected prompt, and receive response\n",
    "\n",
    "\n",
    "def generate_response_with_injected_prompt(user_prompt, corpus, model):\n",
    "# Generates a response using a model with injected prompt from RAG results.\n",
    "\n",
    "# Parameters:\n",
    "# - user_prompt (str): The user's input prompt (e.g., preferences for coffee).\n",
    "# - corpus (list): The corpus of documents to search for similarities.\n",
    "# - model (object): The model used to generate content based on the injected prompt.\n",
    "\n",
    "    # Returns:\n",
    "    # - str: The model-generated response based on the injected prompt.\n",
    "    \n",
    "    # RAG result on the user's input\n",
    "    rag_result = return_response(user_prompt, corpus)\n",
    "    \n",
    "    # View five most similar documents from corpus according to jaccard similarity\n",
    "    print(rag_result)\n",
    "    \n",
    "    # Append input to create an injected prompt\n",
    "    injected_prompt = f\"{user_prompt} {rag_result}\"\n",
    "    \n",
    "    # Call your model and input the injected prompt\n",
    "    response = model.generate_content(injected_prompt)\n",
    "    \n",
    "    # Return the response text\n",
    "    return response.text\n",
    "\n",
    "\"\"\"\n",
    "# Create a TextArea widget to display the code\n",
    "code_widget = widgets.Textarea(\n",
    "    value=code_snippet,\n",
    "    placeholder='Python code',\n",
    "    description='Code:',\n",
    "    disabled=True,  # Disable editing to make it read-only\n",
    "    layout=widgets.Layout(width='1000px', height='250px')  # Adjust size as needed\n",
    ")\n",
    "\n",
    "# Display the widget\n",
    "display(code_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a637166ae670441a8bb2b40b6e7970dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='\\n# Test the function `generate_response_with_injected_prompt`\\n\\n# Sample user input\\nuser_pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the Python code you want users to copy\n",
    "code_snippet = \"\"\"\n",
    "# Test the function `generate_response_with_injected_prompt`\n",
    "\n",
    "# Sample user input\n",
    "user_prompt = \"I like dark roast, espresso coffee. I prefer chocolate and rich flavors.\"\n",
    "\n",
    "print(generate_response_with_injected_prompt(user_prompt, corpus, model))\n",
    "\n",
    "\"\"\"\n",
    "# Create a TextArea widget to display the code\n",
    "code_widget = widgets.Textarea(\n",
    "    value=code_snippet,\n",
    "    placeholder='Python code',\n",
    "    description='Code:',\n",
    "    disabled=True,  # Disable editing to make it read-only\n",
    "    layout=widgets.Layout(width='1000px', height='150px')  # Adjust size as needed\n",
    ")\n",
    "\n",
    "# Display the widget\n",
    "display(code_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Performance Testing - Test the virtual on the use cases provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample use cases from xls file\n",
    "\n",
    "# Pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Safety and Ethical Review - Test the model for safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ethics testing shit (Probably from HuggingFace)\n",
    "\n",
    "# Pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outro..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [ Back to Learning Instructions 5](../learning-instructions-5.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ailtk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
