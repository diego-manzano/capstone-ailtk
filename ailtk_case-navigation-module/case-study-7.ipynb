{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (7) Monitor and improve Virtual Agent performance\n",
    "##### (GenAI Life Cycle Phase 7: Deployment self-assesment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b83668431af498880968f07f769d04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(HTML(value='<h3 style=\\'color: #1e7e34;\\'>PRE-READING: Solution for \"(6) Connect tuned models to…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# LLM and Web App Integration Content\n",
    "llm_webapp_data = [\n",
    "    [\n",
    "        \"<b>(6) Connect tuned models to web applications:</b>\",\n",
    "        (\n",
    "            \"\"\"\n",
    "            <div>\n",
    "                <p>After fine-tuning your LLM, the next step is to deploy it as a web application. \n",
    "                This allows users to interact with the model through a user-friendly interface, \n",
    "                making it accessible for various applications such as chatbots, recommendation systems, \n",
    "                and automated content generation.</p>\n",
    "                \n",
    "                <p>Below is a code segment for deploying a fine-tuned LLM as a web service:</p>\n",
    "                <div style='border: 1px dashed #1e7e34; padding: 10px; margin-top: 10px;'>\n",
    "                    <b>Code Segment:</b>\n",
    "                    <pre style='background-color: #f8f9fa; border: 1px solid #ccc; padding: 10px; font-family: monospace;'>\n",
    "# Import required modules\n",
    "import google.generativeai as genai\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "# TODO: Provide your Gemini API key\n",
    "API_KEY = \"YOUR_GEMINI_API_KEY\"\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "# Define model configuration\n",
    "generation_config = {\n",
    "    \"temperature\": 1,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 40,\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "# Define the virtual assistant's system instruction\n",
    "MODEL = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-pro\",\n",
    "    generation_config=generation_config,\n",
    "    system_instruction=\\\"\\\"\\\"You are a virtual assistant designed to provide accurate and \n",
    "    context-aware responses. Your goal is to assist users efficiently through a web application.\\\"\\\"\\\"\n",
    ")\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/generate\", methods=[\"POST\"])\n",
    "def generate_response():\n",
    "    user_input = request.json.get(\"query\", \"\")\n",
    "    if not user_input:\n",
    "        return jsonify({\"error\": \"No query provided\"}), 400\n",
    "\n",
    "    response = MODEL.generate_content(user_input)\n",
    "    return jsonify({\"response\": response.text})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n",
    "                    </pre>\n",
    "                </div>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        )\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Create content for the widget\n",
    "llm_webapp_content = widgets.VBox([widgets.HTML(value=f\"{item[0]}<br>{item[1]}\") for item in llm_webapp_data])\n",
    "\n",
    "# Styled Box for LLM and Web App Deployment\n",
    "styled_llm_webapp_box = widgets.Box(\n",
    "    [\n",
    "        widgets.HTML(\n",
    "            value=\"<h3 style='color: #1e7e34;'>PRE-READING: Solution for \\\"(6) Connect tuned models to web applications\\\"</h3>\"\n",
    "        ),\n",
    "        widgets.HTML(value=\"<hr style='border: 1px solid #1e7e34;'>\"),  # Horizontal line for separation\n",
    "        llm_webapp_content,\n",
    "    ],\n",
    "    layout=widgets.Layout(\n",
    "        border=\"2px solid #1e7e34\",\n",
    "        padding=\"20px\",\n",
    "        width=\"90%\",\n",
    "        margin=\"20px 0px\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the styled box\n",
    "display(styled_llm_webapp_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (7) Connect tuned models to web applications\n",
    "##### (GenAI Life Cycle Phase 7: Monitoring and Improvement self-assesment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Case Scenario**\n",
    ">\n",
    "> Welp’s restaurant recommendation virtual assistant is now live, helping users find dining options tailored to their preferences. However, launching the virtual agent is just the beginning—ensuring continuous improvement based on real user interactions is essential to maintaining accuracy, relevance, and user satisfaction. As users interact with the AI, their feedback, ratings, and behavioral data provide valuable insights into how well the assistant meets their needs.\n",
    ">\n",
    "> As the AI developer, your task is to implement a monitoring system that collects and analyzes user feedback, allowing you to refine the virtual agent’s performance over time. This includes tracking the accuracy of restaurant recommendations, identifying patterns in user satisfaction, and leveraging Retrieval-Augmented Generation (RAG) enhancements to provide better responses. Additionally, the system should detect recurring issues, such as biased recommendations, incorrect suggestions, or misinterpretations, and provide mechanisms for improving the model accordingly.\n",
    ">\n",
    "> Your Tasks:\n",
    ">\n",
    "> (a) Analyze feedback data\n",
    "> Develop a structured approach to evaluate feedback trends, detect areas for improvement, and update the AI’s knowledge base accordingly. Identify common user concerns, such as incorrect location filtering, mismatched cuisine preferences, or unhelpful suggestions.\n",
    ">\n",
    "> By the end of this activity, you will have gained hands-on experience in monitoring AI performance, analyzing user feedback, and implementing continuous improvements to ensure Welp’s virtual assistant remains effective, unbiased, and user-friendly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-requisites:\n",
    "- Create a Jupyter Notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the tasks as follows:\n",
    "\n",
    "#### **(a) Analyze feedback data**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A sample export of the Welp Virtual Agent's feedback data is available to you. For your Python analysis, access the following file with the filepath:\n",
    "    - `/home/ailtk-learner/Documents/GitHub/capstone-ailtk/ailtk_case-navigation-module/case-files/yelp_academic_dataset_business.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ##### SOLUTION :\n",
    ">> <a href='case-files/ailtk-running-code-case-7.ipynb' target='_blank'>Click here to open Solution: Case Study 7 in Visual Studio Code</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may reference this checklist to self-check your output for this Case Study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a31fd98633c46e5b8df890f73aaf78d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, layout=Layout(width='auto')), Label(value='Have you successfully loaded t…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3200f46c23d44c5c90952784dd387ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, layout=Layout(width='auto')), Label(value='Did you inspect the dataset st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0782c6e283147f9907f53c614242e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, layout=Layout(width='auto')), Label(value='Have you generated a word clou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebf221983bc34e0db044d6a4c62f7cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, layout=Layout(width='auto')), Label(value='Have you generated a word clou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb86deccc954321bc2a363401a404ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, layout=Layout(width='auto')), Label(value='Did you analyze the distributi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b98067c0c12d4eae8efe4bb3974107bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, layout=Layout(width='auto')), Label(value='Have you checked for toxic or …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6add1fe130294f778239e8a10b7c8078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, layout=Layout(width='auto')), Label(value=\"Did you preprocess the 'additi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3fb1dcb8ae4654a2960bd26a25621f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, layout=Layout(width='auto')), Label(value='Have you performed an analysis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4624973274ed4e03a8ae6bf8016f1661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, layout=Layout(width='auto')), Label(value='Did you summarize the recurrin…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b38b830e5114a5792cf92d979872ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, layout=Layout(width='auto')), Label(value='Have you categorized frequent …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56332afbd32846e0a44898eaf20c0c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "checklist_items = [\n",
    "    \"Have you successfully loaded the user feedback dataset into a Pandas DataFrame?\",\n",
    "    \"Did you inspect the dataset structure and identify key columns (e.g., prompt, response, feedback_type, additional_feedback)?\",\n",
    "    \"Have you generated a word cloud for user prompts to identify common queries?\",\n",
    "    \"Have you generated a word cloud for responses to analyze frequently used terms?\",\n",
    "    \"Did you analyze the distribution of feedback types (e.g., thumbs-up vs. thumbs-down) using a bar graph?\",\n",
    "    \"Have you checked for toxic or unsafe responses using a toxicity detection tool?\",\n",
    "\n",
    "    \"Did you preprocess the 'additional_feedback' text (lowercasing, stopword removal, lemmatization)?\",\n",
    "    \"Have you performed an analysis to identify common phrases and key feedback themes (i.e. n-gram analysis)?\",\n",
    "    \"Did you summarize the recurring issues mentioned in user feedback?\",\n",
    "\n",
    "    \"Have you categorized frequent issues (e.g., irrelevant responses, bias, lack of personalization)?\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create checklist widgets with wrapping enabled\n",
    "checkboxes = [widgets.Checkbox(value=False, description=\"\", layout=widgets.Layout(width='auto')) for _ in checklist_items]\n",
    "labels = [widgets.Label(value=item) for item in checklist_items]\n",
    "\n",
    "# Output widget for completion message\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to check if all items are marked\n",
    "def check_completion(change):\n",
    "    if all(cb.value for cb in checkboxes):  # If all checkboxes are checked\n",
    "        with output:\n",
    "            clear_output()\n",
    "            display(HTML('<p style=\"color: green; font-weight: bold;\">✅ You have successfully covered all key points!</p>'))\n",
    "    else:\n",
    "        with output:\n",
    "            clear_output()\n",
    "\n",
    "# Attach event listeners to checkboxes\n",
    "for cb in checkboxes:\n",
    "    cb.observe(check_completion, 'value')\n",
    "\n",
    "# Display checklist with labels for proper text wrapping\n",
    "checklist_ui = [widgets.HBox([cb, label]) for cb, label in zip(checkboxes, labels)]\n",
    "display(*checklist_ui, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer the following to proceed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0969e9876934559a7a038f65f5c221e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q1: What is the primary purpose of monitoring a virtual agent’s performance?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86626a345d5c48fc9159ee7a2c1c4a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=('To collect user data for marketing purposes'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14205625996f489892bb58b3cfcf9e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q2: Which of the following is a key source of feedback for improving a virtual assistant?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0486d53b67e48c28a1b5710d1e12d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=('Server logs and API call response times', 'U…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0feebf5c8c44f4da852c96ec99938e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q3: What is a common issue that can arise if a virtual assistant is not regularly updated?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe46683e33be4bcfbb0af6ef122e9dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=('Users may have to wait longer for responses'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ea2f93f8124868acd17a211f9cb791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q4: How can Retrieval-Augmented Generation (RAG) help improve the accuracy of a virtual assistant…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e617eb1064d4b9e928d1f2f0f52a136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=('By replacing all model-generated responses w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9db6fe832d74627aaee6820be6a4cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q5: What is an effective strategy for keeping a virtual agent’s knowledge base updated?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b73c470668fb4a5ca3106b5bee0d338c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=('Regularly fine-tuning the model with recent …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75610e1922bf416a994dd2855e90999e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Submit Answers', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9beffaf3ae406a9f09f4789889ffb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Define questions and options\n",
    "questions = [\n",
    "    {\n",
    "        \"question\": \"What is the primary purpose of monitoring a virtual agent’s performance?\",\n",
    "        \"options\": [\n",
    "            \"To collect user data for marketing purposes\",\n",
    "            \"To ensure the AI continues to provide accurate, relevant, and user-friendly recommendations\",\n",
    "            \"To track how many users interact with the system\",\n",
    "            \"To prevent users from submitting feedback\"\n",
    "        ],\n",
    "        \"answer\": \"To ensure the AI continues to provide accurate, relevant, and user-friendly recommendations\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which of the following is a key source of feedback for improving a virtual assistant?\",\n",
    "        \"options\": [\n",
    "            \"Server logs and API call response times\",\n",
    "            \"User satisfaction ratings, comments, and behavioral data\",\n",
    "            \"The number of times a user refreshes the page\",\n",
    "            \"Competitor AI models\"\n",
    "        ],\n",
    "        \"answer\": \"User satisfaction ratings, comments, and behavioral data\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is a common issue that can arise if a virtual assistant is not regularly updated?\",\n",
    "        \"options\": [\n",
    "            \"Users may have to wait longer for responses\",\n",
    "            \"The assistant may provide outdated or irrelevant recommendations\",\n",
    "            \"The AI will start generating random responses\",\n",
    "            \"The assistant will automatically shut down\"\n",
    "        ],\n",
    "        \"answer\": \"The assistant may provide outdated or irrelevant recommendations\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How can Retrieval-Augmented Generation (RAG) help improve the accuracy of a virtual assistant’s responses?\",\n",
    "        \"options\": [\n",
    "            \"By replacing all model-generated responses with static pre-written answers\",\n",
    "            \"By retrieving and integrating the most up-to-date and relevant information into responses\",\n",
    "            \"By reducing the number of queries the AI can process\",\n",
    "            \"By preventing users from submitting additional feedback\"\n",
    "        ],\n",
    "        \"answer\": \"By retrieving and integrating the most up-to-date and relevant information into responses\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is an effective strategy for keeping a virtual agent’s knowledge base updated?\",\n",
    "        \"options\": [\n",
    "            \"Regularly fine-tuning the model with recent data and user feedback\",\n",
    "            \"Deleting old user feedback to make space for new data\",\n",
    "            \"Allowing the model to update itself without oversight\",\n",
    "            \"Ignoring user feedback and relying only on the initial dataset\"\n",
    "        ],\n",
    "        \"answer\": \"Regularly fine-tuning the model with recent data and user feedback\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Widgets for questions\n",
    "quiz_widgets = []\n",
    "for i, q in enumerate(questions):\n",
    "    question_label = widgets.Label(value=f\"Q{i+1}: {q['question']}\")\n",
    "    options = widgets.RadioButtons(\n",
    "        options=q['options'],\n",
    "        description='',\n",
    "        disabled=False,\n",
    "        value=None,\n",
    "        layout=widgets.Layout(width='90%', height='auto')\n",
    "    )\n",
    "    quiz_widgets.append((question_label, options))\n",
    "\n",
    "# Button to submit answers\n",
    "submit_button = widgets.Button(description=\"Submit Answers\", button_style=\"primary\")\n",
    "output = widgets.Output()\n",
    "\n",
    "# Define button click event\n",
    "def on_submit_click(b):\n",
    "    submit_button.disabled = True\n",
    "    clear_output(wait=True)\n",
    "    unanswered = False\n",
    "    score = 0\n",
    "\n",
    "    for i, (label, options) in enumerate(quiz_widgets):\n",
    "        if options.value is None:\n",
    "            unanswered = True\n",
    "\n",
    "    with output:\n",
    "        if unanswered:\n",
    "            display(widgets.HTML(\n",
    "                '<p style=\"color: red; font-weight: bold;\">Please answer all the questions before submitting.</p>'\n",
    "            ))\n",
    "            submit_button.disabled = False\n",
    "        else:\n",
    "            for i, (label, options) in enumerate(quiz_widgets):\n",
    "                user_answer = options.value\n",
    "                correct_answer = questions[i][\"answer\"]\n",
    "                if user_answer == correct_answer:\n",
    "                    score += 1\n",
    "                print(f\"Q{i+1}: {questions[i]['question']}\")\n",
    "                print(f\"  - Your answer: {user_answer}\")\n",
    "                print(f\"  - Correct answer: {correct_answer}\\n\")\n",
    "\n",
    "            print(f\"You scored {score}/{len(questions)}! ({(score / len(questions)) * 100:.2f}%)\")\n",
    "            \n",
    "            if score >= 0.8 * len(questions):\n",
    "                display(widgets.HTML(\n",
    "                    '<a href=\"case-landing.ipynb\" style=\"display: inline-block; padding: 10px 15px; '\n",
    "                    'background-color: #28a745; color: white; text-decoration: none; border-radius: 5px;\">'\n",
    "                    'Continue</a>'\n",
    "                ))\n",
    "            else:\n",
    "                display(widgets.HTML(\n",
    "                    '<a href=\"case-study-7.ipynb\" style=\"display: inline-block; padding: 10px 15px; '\n",
    "                    'background-color: #dc3545; color: white; text-decoration: none; border-radius: 5px;\">'\n",
    "                    'Score at least 80% to continue. Try Again</a>'\n",
    "                ))\n",
    "\n",
    "# Attach event to the submit button\n",
    "submit_button.on_click(on_submit_click)\n",
    "\n",
    "# Display the quiz\n",
    "for label, options in quiz_widgets:\n",
    "    display(label, options)\n",
    "display(submit_button, output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ailtk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
