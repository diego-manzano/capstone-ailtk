{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution\n",
    "# (7) Practice Learning Activity: Monitor and improve Virtual Agent performance through user satisfaction ratings and feedback\n",
    "##### (GenAI Life Cycle Phase 7: Monitoring and Improvement self-practice)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from detoxify import Detoxify\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Load CSV file into a pandas DataFrame\n",
    "csv_path = \"/home/ailtk-learner/Documents/GitHub/capstone-ailtk/case-navigation-module/case-files/yelp_academic_dataset_business.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Preview the dataset\n",
    "print(df.head())\n",
    "\n",
    "# ---- WORD CLOUD: REVIEWS ----\n",
    "plt.figure(figsize=(8, 6))\n",
    "review_text = \" \".join(df[\"review\"].dropna().astype(str))  # Adjust column name if necessary\n",
    "wordcloud_reviews = WordCloud(width=600, height=400, background_color=\"white\", colormap=\"viridis\").generate(review_text)\n",
    "plt.imshow(wordcloud_reviews, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Word Cloud: Reviews\")\n",
    "plt.show()\n",
    "\n",
    "# ---- TOXICITY ANALYSIS ----\n",
    "detoxify_model = Detoxify('original')\n",
    "toxicity_threshold = 0.5\n",
    "toxicity_scores_list = []\n",
    "\n",
    "for i, review in enumerate(df['review'].dropna()):  # Adjust column name if necessary\n",
    "    toxicity_scores = detoxify_model.predict(review)\n",
    "    toxicity_scores = {key: float(value) for key, value in toxicity_scores.items()}\n",
    "    toxicity_scores_list.append(toxicity_scores)\n",
    "\n",
    "    if any(score > toxicity_threshold for score in toxicity_scores.values()):\n",
    "        print(f\"Warning: Potentially unsafe content detected in review {i}.\")\n",
    "        print(f\"Details: {toxicity_scores}\")\n",
    "\n",
    "# Convert the toxicity scores list to a DataFrame\n",
    "toxicity_df = pd.DataFrame(toxicity_scores_list)\n",
    "\n",
    "# ---- HEATMAP: TOXICITY SCORES ----\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(toxicity_df, annot=True, cmap=sns.color_palette(\"coolwarm\", as_cmap=True), vmin=0, vmax=1, cbar=True)\n",
    "plt.title('Toxicity Scores Heatmap')\n",
    "plt.xlabel('Toxicity Categories')\n",
    "plt.ylabel('Reviews')\n",
    "plt.show()\n",
    "\n",
    "# ---- FEEDBACK DISTRIBUTION ----\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(data=df, x=\"stars\", palette=\"coolwarm\")  # Adjust column name if necessary\n",
    "plt.title(\"Review Rating Distribution\")\n",
    "plt.xlabel(\"Stars\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# ---- TEXT PREPROCESSING ----\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df_cleaned = df['review'].dropna().apply(preprocess_text)  # Adjust column name if necessary\n",
    "\n",
    "# ---- BIGRAM ANALYSIS ----\n",
    "vectorizer = CountVectorizer(ngram_range=(2, 2), stop_words='english')\n",
    "X = vectorizer.fit_transform(df_cleaned)\n",
    "ngram_freq = X.toarray().sum(axis=0)\n",
    "ngram_terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "ngram_df = pd.DataFrame(list(zip(ngram_terms, ngram_freq)), columns=[\"Bigram\", \"Frequency\"])\n",
    "ngram_df = ngram_df.sort_values(by=\"Frequency\", ascending=False)\n",
    "\n",
    "print(ngram_df.head(10))\n",
    "\n",
    "# ---- FILTER REVIEWS WITH SPECIFIC BIGRAMS ----\n",
    "bigrams_to_check = ['customer service', 'needs better']\n",
    "\n",
    "def contains_bigram(text, bigrams):\n",
    "    if isinstance(text, str):\n",
    "        return any(bigram in text for bigram in bigrams)\n",
    "    return False\n",
    "\n",
    "filtered_df = df[df['review'].notna() & df['review'].apply(lambda x: contains_bigram(x, bigrams_to_check))]\n",
    "\n",
    "# Display filtered entries\n",
    "print(filtered_df)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
