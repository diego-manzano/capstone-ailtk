{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) Case Study: Evaluate models on use cases and for safety\n",
    "##### (GenAI Life Cycle Phase 5: Evaluation self-assesment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d80bbcff114e3288bb60b5937c9b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(HTML(value='<h3 style=\\'color: #1e7e34;\\'>PRE-READING: Solution of \"(4) Case Study: Accessing clâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Cloud-Based LLM and RAG Content\n",
    "cloud_llm_rag_data = [\n",
    "    [\n",
    "        \"<b>(4a) Prompt Engineering in Google AI Studio:</b>\",\n",
    "        (\n",
    "            \"\"\"\n",
    "            <div>\n",
    "                <p>You should have designed and refined your own prompt in Google AI Studio to ensure the Gemini model \n",
    "                accurately interprets user intents and generates contextually relevant responses.</p>\n",
    "                <p>Below is a code segment you can use with a prompt usable for the given case:</p>\n",
    "                <div style='border: 1px dashed #1e7e34; padding: 10px; margin-top: 10px;'>\n",
    "                    <b>Code Segment:</b>\n",
    "                    <pre style='background-color: #f8f9fa; border: 1px solid #ccc; padding: 10px; font-family: monospace;'>\n",
    "# Import Google GenerativeAI Python module\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Define Gemini API key\n",
    "genai.configure(api_key=\"YOUR_GEMINI_API_KEY\")\n",
    "\n",
    "# Create the model\n",
    "generation_config = {\n",
    "  \"temperature\": 1,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 40,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "# Specify model name and define system instruction\n",
    "model = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-pro\",\n",
    "  generation_config=generation_config,\n",
    "  system_instruction=\\\"\\\"\\\"You are a virtual restaurant and bar recommendation assistant. Your goal is to provide users with highly personalized recommendations based on their preferences and needs.\n",
    "\n",
    "Here are some guidelines to follow:\n",
    "\n",
    "- Understand the User's Intent: Carefully analyze the user's query.\n",
    "- Leverage User Preferences: Utilize the user's past behavior.\n",
    "- Consider Dietary Restrictions: Factor in dietary restrictions.\n",
    "- Provide Relevant Information: Offer details like cuisine type, price, and ambiance.\n",
    "- Handle Ambiguous Queries: Ask clarifying questions.\n",
    "- Be Conversational and Engaging: Maintain a friendly tone.\\\"\\\"\\\"\n",
    ")\n",
    "\n",
    "# Acceptable past chat for reference\n",
    "chat_session = model.start_chat(\n",
    "  history=[\n",
    "    {\"role\": \"user\", \"parts\": [\"Hello\"]},\n",
    "    {\"role\": \"model\", \"parts\": [\"Hello there! I am a virtual agent for Welp!\"]},\n",
    "  ]\n",
    ")\n",
    "                    </pre>\n",
    "                </div>\n",
    "                <div style='margin-top: 10px;'>\n",
    "                    <a href='case-files/ailtk-running-code-case-4.ipynb' target='_blank' style='color: #1e7e34; text-decoration: underline;'>Click here to open Solution: Case Study 4 in Visual Studio Code</a>\n",
    "                </div>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        )\n",
    "    ],\n",
    "    [\n",
    "        \"<b>(4b) API Integration:</b>\",\n",
    "        (\n",
    "            \"You will be able to reuse your API key from Practice Learning Activity 4 for the sake of this case.<br>\"\n",
    "            \"<div style='margin-top: 10px;'>\"\n",
    "            \"<a href='#' target='_blank' style='color: #1e7e34; text-decoration: underline;'>Click here to review receiving and accessing your API key</a>\"\n",
    "            \"</div>\"\n",
    "        )\n",
    "    ],\n",
    "    [\n",
    "        \"<b>(4c) Data Utilization with RAG:</b>\",\n",
    "        (\n",
    "            \"Apply Retrieval-Augmented Generation (RAG) techniques to combine the fine-tuned Gemini model with curated datasets.<br>\"\n",
    "            \"<div style='border: 1px dashed #1e7e34; padding: 10px; margin-top: 10px;'>\"\n",
    "            \"<b>Code Segment:</b><br><pre style='background-color: #f8f9fa; border: 1px solid #ccc; padding: 10px; font-family: monospace;'>\"\n",
    "            \"\"\"\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(\"solution-case-study-activity-3/ailtk-case-apache-hop-output.xls\")\n",
    "\n",
    "# Combine relevant columns into a single document per row\n",
    "# Assuming the columns are 'input' and 'output', adjust if necessary\n",
    "corpus = df.apply(lambda row: f\"{row['input']}. {row['output']}\", axis=1).tolist()\n",
    "\n",
    "# Save corpus to a pickle file\n",
    "PICKLE_FILE = \"corpus.pkl\"\n",
    "\n",
    "with open(PICKLE_FILE, \"wb\") as f:\n",
    "    pickle.dump(corpus, f)\n",
    "\n",
    "print(f\"Corpus successfully saved to {PICKLE_FILE}\")\n",
    "\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "class RAGOrchestrator:\n",
    "    # Manages corpus loading, similarity calculations, and generating augmented responses using the LLM.\n",
    "\n",
    "    def __init__(self, pickle_file: str, model):\n",
    "        # Initializes the RAGOrchestrator.\n",
    "        # Parameters:\n",
    "        # - pickle_file (str): Path to the pickled corpus file.\n",
    "        # - model: Preloaded LLM instance for generating responses.\n",
    "\n",
    "        self.pickle_file = pickle_file\n",
    "        self.model = model\n",
    "        self.corpus = self._load_corpus()\n",
    "\n",
    "    def _load_corpus(self) -> List[str]:\n",
    "        # Loads the corpus from a pickle file.\n",
    "        \n",
    "        if not os.path.exists(self.pickle_file):\n",
    "            raise FileNotFoundError(f\"Pickle file '{self.pickle_file}' not found. Please generate it first.\")\n",
    "        \n",
    "        with open(self.pickle_file, \"rb\") as f:\n",
    "            print(\"Corpus loaded from pickle file.\")\n",
    "            return pickle.load(f)\n",
    "\n",
    "    @staticmethod\n",
    "    def _jaccard_similarity(query: str, document: str) -> float:\n",
    "        # Calculates Jaccard similarity between a query and a document.\n",
    "        \n",
    "        query_tokens = set(query.lower().split())\n",
    "        document_tokens = set(document.lower().split())\n",
    "        \n",
    "        intersection = query_tokens.intersection(document_tokens)\n",
    "        union = query_tokens.union(document_tokens)\n",
    "\n",
    "        return len(intersection) / len(union) if union else 0.0\n",
    "\n",
    "    def _get_similar_documents(self, query: str, top_n: int = 5) -> List[str]:\n",
    "        # Retrieves the top N most similar documents from the corpus.\n",
    "        \n",
    "        similarities = [self._jaccard_similarity(query, doc) for doc in self.corpus]\n",
    "        top_indices = sorted(range(len(similarities)), key=lambda i: similarities[i], reverse=True)[:top_n]\n",
    "        \n",
    "        return [self.corpus[i] for i in top_indices]\n",
    "\n",
    "    def generate_augmented_response(self, user_prompt: str) -> str:\n",
    "        # Generates a response using the LLM with an injected prompt from RAG results.\n",
    "\n",
    "        similar_docs = self._get_similar_documents(user_prompt)\n",
    "        injected_prompt = f\"{user_prompt} {' '.join(similar_docs)}\"\n",
    "\n",
    "        response = self.model.generate_content(injected_prompt)\n",
    "        return response.text\n",
    "\n",
    "# Example usage:\n",
    "# PICKLE_FILE = \"corpus.pkl\"\n",
    "# MODEL = genai.GenerativeModel(model_name=\"gemini-1.5-flash\", generation_config=generation_config)\n",
    "# orchestrator = RAGOrchestrator(PICKLE_FILE, MODEL)\n",
    "# response = orchestrator.generate_augmented_response(\"Tell me about restaurant recommendations\")\n",
    "# print(response)\n",
    "\n",
    "\n",
    "            \"\"\"\n",
    "            \"</pre></div>\"\n",
    "        )\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Create content for the widget\n",
    "cloud_llm_rag_content = widgets.VBox([widgets.HTML(value=f\"{item[0]}<br>{item[1]}\") for item in cloud_llm_rag_data])\n",
    "\n",
    "# Styled Box for Cloud-Based LLM and RAG\n",
    "styled_cloud_llm_box = widgets.Box(\n",
    "    [\n",
    "        widgets.HTML(\n",
    "            value=\"<h3 style='color: #1e7e34;'>PRE-READING: Solution of \\\"(4) Case Study: Accessing cloud-based LLM models and implementing RAG\\\"</h3>\"\n",
    "        ),\n",
    "        widgets.HTML(value=\"<hr style='border: 1px solid #1e7e34;'>\"),  # Horizontal line for separation\n",
    "        cloud_llm_rag_content,\n",
    "    ],\n",
    "    layout=widgets.Layout(\n",
    "        border=\"2px solid #1e7e34\",\n",
    "        padding=\"20px\",\n",
    "        width=\"90%\",\n",
    "        margin=\"20px 0px\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the styled box\n",
    "display(styled_cloud_llm_box)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case Scenario\n",
    "> Welp's restaurant recommendation virtual assistant has now progressed to the evaluation phase, where its capabilities and safety must be thoroughly tested to ensure it meets real-world demands and adheres to ethical AI guidelines. With its Retrieval-Augmented Generation (RAG) system integrated, the assistant can provide personalized restaurant suggestions and contextual justifications. However, it is essential to confirm that these recommendations are accurate, inclusive, and aligned with user expectations.\n",
    ">\n",
    "> As the AI developer, your task is to evaluate the assistantâ€™s performance across various use cases. This includes testing its ability to handle diverse user inputsâ€”ranging from vague or incomplete queries to specific and detailed requests. Additionally, you must assess the assistant's adherence to ethical AI principles, such as avoiding biased or discriminatory suggestions, and ensuring that its responses remain neutral and user-focused.\n",
    ">\n",
    "> The virtual assistant must also maintain a professional and approachable tone, consistent with Welp's branding, to instill trust and encourage user engagement.\n",
    ">\n",
    "> Your Tasks:\n",
    "> \n",
    "> (a) Performance Evaluation:\n",
    "> Test the virtual assistantâ€™s accuracy and relevance in delivering restaurant recommendations across multiple scenarios, including users with dietary restrictions, specific cuisine preferences, or location constraints. Analyze edge cases, such as conflicting user inputs or ambiguous requests.\n",
    ">\n",
    ">(b) Safety and Ethical Testing:\n",
    "> Examine the assistantâ€™s outputs for potential biases or safety concerns. For instance, verify that the assistant does not promote unhealthy eating habits or unfairly prioritize certain restaurant categories over others. Additionally, ensure that its recommendations remain respectful and appropriate for diverse cultural contexts.\n",
    "> \n",
    "> By the end of this activity, you will have applied best practices for model evaluation, gaining hands-on experience in ensuring that AI systems are not only functional but also safe, ethical, and aligned with user needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-requisite:\n",
    "- Create a Jupyter Notebook and load your code for RAG (from the previous Chapter.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the tasks as follows:\n",
    "\n",
    "\n",
    "#### **(a) Performance Evaluation:** Test the virtual assistantâ€™s accuracy and relevance in delivering restaurant recommendations across multiple scenarios, including users with dietary restrictions, specific cuisine preferences, or location constraints.\n",
    "\n",
    "- <a href='case-files/ailtk-usecases.xlsx' target='_blank'>Find use cases here</a>\n",
    "\n",
    "#### **(b) Safety and Ethical Testing:** Examine the assistantâ€™s outputs for potential biases or safety concerns.\n",
    "\n",
    "- <a href='https://huggingface.co/datasets?task_categories=task_categories:question-answering&sort=trending' target='_blank'>Find more use cases for (b) Safety and Ethical Testing here</a>\n",
    "\n",
    "- <a href='https://huggingface.co/collections/harpreetsahota/red-teaming-prompts-656256235475849b82a91813' target='_blank'>And here</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ##### SOLUTION :\n",
    ">> <a href='case-files/ailtk-running-code-case-5.ipynb' target='_blank'>Click here to open Solution: Case Study 5 in Visual Studio Code</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may reference this checklist to self-check your output for this Case Study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5577592b7de4edbad8e9b76ae82660c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, layout=Layout(width='auto')), Label(value='(5a) Performance Evaluation: Hâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92d9c78d54145aea539d7051a6fa46b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, layout=Layout(width='auto')), Label(value='(5a) Performance Evaluation: Dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f37e835d28554e32a0901c2b67c9ed51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, layout=Layout(width='auto')), Label(value='(5a) Performance Evaluation: Hâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b2b3b93465840f5b3eb0ab848057529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, layout=Layout(width='auto')), Label(value='(5a) Performance Evaluation: Dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfcbc31232e24c599ad376a5ecf74e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, layout=Layout(width='auto')), Label(value='(5a) Performance Evaluation: Hâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4e90a508f8a46e3ab8a3dccdee9f08a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, layout=Layout(width='auto')), Label(value='(5b) Safety and Ethical Testinâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "078c8da4f9cc41fe9ba7fbefd2868e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, layout=Layout(width='auto')), Label(value='(5b) Safety and Ethical Testinâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0183d8da5c423a94d819e250bc654d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, layout=Layout(width='auto')), Label(value='(5b) Safety and Ethical Testinâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eebcf2ad275544728c1f66a11d13f968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, layout=Layout(width='auto')), Label(value='(5b) Safety and Ethical Testinâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d197c941b04b499dbff3ef38a931a51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, layout=Layout(width='auto')), Label(value='(5b) Safety and Ethical Testinâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d293b6eeb64925a9a25d58a9ecdee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, layout=Layout(width='auto')), Label(value='(5b) Safety and Ethical Testinâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3489cc39d0c9496bacb7e2bf6bb1117b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, layout=Layout(width='auto')), Label(value='(5b) Safety and Ethical Testinâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7775650c1f4544c4ad8433205dc6f2d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "# Define checklist items based on key learning points\n",
    "checklist_items = [\n",
    "    \"(5a) Performance Evaluation: Have you tested the virtual assistantâ€™s accuracy and relevance in delivering restaurant recommendations across multiple scenarios (e.g., dietary restrictions, cuisine preferences, location constraints)?\",\n",
    "    \"(5a) Performance Evaluation: Did you analyze edge cases, such as conflicting user inputs or ambiguous requests, to assess the modelâ€™s robustness?\",\n",
    "    \"(5a) Performance Evaluation: Have you selected a diverse set of sample prompts to evaluate the modelâ€™s response quality?\",\n",
    "    \"(5a) Performance Evaluation: Did you implement randomized testing to avoid biases in evaluation results?\",\n",
    "    \"(5a) Performance Evaluation: Have you ensured a cooldown period between queries to prevent rate limits and ensure stable API performance?\",\n",
    "\n",
    "    \"(5b) Safety and Ethical Testing: Have you examined the assistantâ€™s outputs for potential biases in restaurant recommendations (e.g., unfairly favoring specific cuisines or businesses)?\",\n",
    "    \"(5b) Safety and Ethical Testing: Did you verify that the assistant does not promote unhealthy eating habits or unethical behaviors?\",\n",
    "    \"(5b) Safety and Ethical Testing: Have you implemented red teaming by testing the model with both normal and adversarial prompts?\",\n",
    "    \"(5b) Safety and Ethical Testing: Did you use a toxicity detection tool (e.g., Detoxify) to assess responses for harmful or inappropriate content?\",\n",
    "    \"(5b) Safety and Ethical Testing: Have you set a threshold for toxicity scores and flagged any potentially unsafe content?\",\n",
    "    \"(5b) Safety and Ethical Testing: Have you stored and visualized toxicity scores using a heatmap for analysis?\",\n",
    "    \"(5b) Safety and Ethical Testing: Did you ensure that the assistantâ€™s recommendations are appropriate across diverse cultural and ethical contexts?\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Create checklist widgets with wrapping enabled\n",
    "checkboxes = [widgets.Checkbox(value=False, description=\"\", layout=widgets.Layout(width='auto')) for _ in checklist_items]\n",
    "labels = [widgets.Label(value=item) for item in checklist_items]\n",
    "\n",
    "# Output widget for completion message\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to check if all items are marked\n",
    "def check_completion(change):\n",
    "    if all(cb.value for cb in checkboxes):  # If all checkboxes are checked\n",
    "        with output:\n",
    "            clear_output()\n",
    "            display(HTML('<p style=\"color: green; font-weight: bold;\">âœ… You have successfully covered all key points!</p>'))\n",
    "    else:\n",
    "        with output:\n",
    "            clear_output()\n",
    "\n",
    "# Attach event listeners to checkboxes\n",
    "for cb in checkboxes:\n",
    "    cb.observe(check_completion, 'value')\n",
    "\n",
    "# Display checklist with labels for proper text wrapping\n",
    "checklist_ui = [widgets.HBox([cb, label]) for cb, label in zip(checkboxes, labels)]\n",
    "display(*checklist_ui, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer the following to proceed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763ec08bfa814e8b9efd59ad8bffecb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q1: What is the primary goal of performance testing?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1b6baee00d4e398cf18e2d5f3f6083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=('To identify edge cases and test model robustâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f7482483d54f98b6656cd0da58524a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q2: Which input should the model evaluate for possible ethical problems?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169b328268a1483b8c4e64b9f0d30578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=('Common user preferences', 'Beginner queries'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0b35d4284546c5a341626b3b73dc77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q3: What is a key task in the safety and ethical review of virtual agents?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd11ee4d54c241028070f72171385a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=('Testing the agent for biases in recommendatiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca73ff3496b408e92729244bdf96cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q4: What should the virtual agent avoid to maintain brand guidelines?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7b13490ef941eaa160402e23c32a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=('Using an overly casual tone', 'Suggesting neâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6dd755690384657abcf33b79231f368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q5: What tool is suggested for identifying potential vulnerabilities in the AI system?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec45c88e52b402090d786de3b722547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=('Red teaming', 'Data augmentation', 'Performaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536b13a746924f74aaaf680119287986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q6: What is the expected behavior of the agent when handling ambiguous inputs?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "febcbea6697d437cb6007d242cc663ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=('It should ask clarifying questions.', 'It shâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18d74b43099447d8f285551567face9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q7: What criteria should the model meet to pass safety evaluations?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf112e26b3745479f13c2f5e7946f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=('Accurate, unbiased, and practical recommendaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d810a2f8744f959426892e7daf6577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q8: What is the purpose of red team prompts in model evaluation?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671af965b9dc4a359a842d4edae0ab26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=('To identify flaws in the modelâ€™s ethical or â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2280a77a555b439d8465b3051a679367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q9: How does the system handle user input that requests unethical actions?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d15cd437754b4332b677e423b6ff6ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=('It denies the request and provides ethical gâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2ba1e876854e448f6f4d6fed8e085f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q10: What is an example of an edge case a model must be evaluated on?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9755d19ccd7945578bec0d734e50fbe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=('Handling contradictory or ambiguous user inpâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcfaf94fae97436dabbf27653453834b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Submit Answers', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0504bca6483a43c99afe5001793e94cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Define questions and options\n",
    "questions = [\n",
    "    {\n",
    "        \"question\": \"What is the primary goal of performance testing?\",\n",
    "        \"options\": [\n",
    "            \"To identify edge cases and test model robustness\",\n",
    "            \"To ensure the agent adheres to ethical AI guidelines\",\n",
    "            \"To simulate scenarios and ensure accurate recommendations\",\n",
    "            \"To train the model on additional industry-specific data\"\n",
    "        ],\n",
    "        \"answer\": \"To simulate scenarios and ensure accurate recommendations\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which input should the model evaluate for possible ethical problems?\",\n",
    "        \"options\": [\n",
    "            \"Common user preferences\",\n",
    "            \"Beginner queries\",\n",
    "            \"Advanced enthusiast requests\",\n",
    "            \"\\\"Red team\\\" prompts and edge cases\"\n",
    "        ],\n",
    "        \"answer\": \"\\\"Red team\\\" prompts and edge cases\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is a key task in the safety and ethical review of virtual agents?\",\n",
    "        \"options\": [\n",
    "            \"Testing the agent for biases in recommendations\",\n",
    "            \"Adding new features for advanced enthusiasts\",\n",
    "            \"Optimizing the agent's response time\",\n",
    "            \"Reducing the corpus size for faster processing\"\n",
    "        ],\n",
    "        \"answer\": \"Testing the agent for biases in recommendations\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What should the virtual agent avoid to maintain brand guidelines?\",\n",
    "        \"options\": [\n",
    "            \"Using an overly casual tone\",\n",
    "            \"Suggesting new possible things to try\",\n",
    "            \"Providing info from the corpus provided\",\n",
    "            \"Recommending unique or less popular options\"\n",
    "        ],\n",
    "        \"answer\": \"Using an overly casual tone\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What tool is suggested for identifying potential vulnerabilities in the AI system?\",\n",
    "        \"options\": [\n",
    "            \"Red teaming\",\n",
    "            \"Data augmentation\",\n",
    "            \"Performance tuning\",\n",
    "            \"Corpus filtering\"\n",
    "        ],\n",
    "        \"answer\": \"Red teaming\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the expected behavior of the agent when handling ambiguous inputs?\",\n",
    "        \"options\": [\n",
    "            \"It should ask clarifying questions.\",\n",
    "            \"It should recommend the most popular spots.\",\n",
    "            \"It should generate a random suggestions.\",\n",
    "            \"It should refer the user to customer support.\"\n",
    "        ],\n",
    "        \"answer\": \"It should ask clarifying questions.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What criteria should the model meet to pass safety evaluations?\",\n",
    "        \"options\": [\n",
    "            \"Accurate, unbiased, and practical recommendations\",\n",
    "            \"Speed of response under 0.5 seconds\",\n",
    "            \"Support for all global languages\",\n",
    "            \"Ability to generate a complete restaurant guide\"\n",
    "        ],\n",
    "        \"answer\": \"Accurate, unbiased, and practical recommendations\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the purpose of red team prompts in model evaluation?\",\n",
    "        \"options\": [\n",
    "            \"To identify flaws in the modelâ€™s ethical or safety handling\",\n",
    "            \"To provide additional training data for the model\",\n",
    "            \"To improve the speed of the recommendation engine\",\n",
    "            \"To add variety to user queries\"\n",
    "        ],\n",
    "        \"answer\": \"To identify flaws in the modelâ€™s ethical or safety handling\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the system handle user input that requests unethical actions?\",\n",
    "        \"options\": [\n",
    "            \"It denies the request and provides ethical guidelines.\",\n",
    "            \"It generates a placeholder response.\",\n",
    "            \"It logs the input for future training.\",\n",
    "            \"It refers the query to a human operator.\"\n",
    "        ],\n",
    "        \"answer\": \"It denies the request and provides ethical guidelines.\"\n",
    "    },\n",
    "    {\n",
    "    \"question\": \"What is an example of an edge case a model must be evaluated on?\",\n",
    "    \"options\": [\n",
    "        \"Handling contradictory or ambiguous user inputs\",\n",
    "        \"Providing information on commonly known topics\",\n",
    "        \"Responding to straightforward, factual queries\",\n",
    "        \"Delivering recommendations within well-defined parameters\"\n",
    "    ],\n",
    "    \"answer\": \"Handling contradictory or ambiguous user inputs\"\n",
    "}\n",
    "]\n",
    "\n",
    "# Widgets for questions\n",
    "quiz_widgets = []\n",
    "for i, q in enumerate(questions):\n",
    "    question_label = widgets.Label(value=f\"Q{i+1}: {q['question']}\")\n",
    "    options = widgets.RadioButtons(\n",
    "        options=q['options'],\n",
    "        description='',\n",
    "        disabled=False,\n",
    "        value=None,\n",
    "        layout=widgets.Layout(width='90%', height='auto')  # Ensures proper layout for longer options\n",
    "    )\n",
    "    quiz_widgets.append((question_label, options))\n",
    "\n",
    "# Button to submit answers\n",
    "submit_button = widgets.Button(description=\"Submit Answers\", button_style=\"primary\")\n",
    "output = widgets.Output()\n",
    "\n",
    "# Flag to track if the error message is already displayed\n",
    "error_displayed = False\n",
    "\n",
    "# Define button click event\n",
    "def on_submit_click(b):\n",
    "    global error_displayed\n",
    "    # Disable the submit button\n",
    "    submit_button.disabled = True\n",
    "    clear_output(wait=True)\n",
    "    unanswered = False\n",
    "    score = 0\n",
    "\n",
    "    # Check if all questions are answered\n",
    "    for i, (label, options) in enumerate(quiz_widgets):\n",
    "        if options.value is None:  # If a question is left unanswered\n",
    "            unanswered = True\n",
    "\n",
    "    with output:\n",
    "        if unanswered:\n",
    "            if not error_displayed:  # Only display the error if it hasn't been shown already\n",
    "                error_displayed = True\n",
    "                # Display error message in red\n",
    "                display(widgets.HTML(\n",
    "                    '<p style=\"color: red; font-weight: bold;\">Please answer all the questions before submitting.</p>'\n",
    "                ))\n",
    "            submit_button.disabled = False  # Re-enable button if there's an error\n",
    "        else:\n",
    "            error_displayed = False  # Reset the flag if all questions are answered\n",
    "            submit_button.button_style = \"\"  # Reset button style to default after click\n",
    "            # Calculate score\n",
    "            for i, (label, options) in enumerate(quiz_widgets):\n",
    "                user_answer = options.value\n",
    "                correct_answer = questions[i][\"answer\"]\n",
    "                if user_answer == correct_answer:\n",
    "                    score += 1\n",
    "                print(f\"Q{i+1}: {questions[i]['question']}\")\n",
    "                print(f\"  - Your answer: {user_answer}\")\n",
    "                print(f\"  - Correct answer: {correct_answer}\")\n",
    "                print()\n",
    "\n",
    "            print(f\"You scored {score}/{len(questions)}! ({(score / len(questions)) * 100:.2f}%)\")\n",
    "            \n",
    "            # Show Continue or Try Again button based on score\n",
    "            if score >= 0.8 * len(questions):\n",
    "                continue_button = widgets.HTML(\n",
    "                    '<a href=\"case-study-6.ipynb\" style=\"display: inline-block; padding: 10px 15px; '\n",
    "                    'background-color: #28a745; color: white; text-decoration: none; border-radius: 5px;\">'\n",
    "                    'Continue</a>'\n",
    "                )\n",
    "                display(continue_button)\n",
    "            else:\n",
    "                try_again_button = widgets.HTML(\n",
    "                    '<a href=\"case-study-5.ipynb\" style=\"display: inline-block; padding: 10px 15px; '\n",
    "                    'background-color: #dc3545; color: white; text-decoration: none; border-radius: 5px;\">'\n",
    "                    'Score at least 80% to continue. Try Again</a>'\n",
    "                )\n",
    "                display(try_again_button)\n",
    "\n",
    "# Attach event to the submit button\n",
    "submit_button.on_click(on_submit_click)\n",
    "\n",
    "# Display the quiz\n",
    "for label, options in quiz_widgets:\n",
    "    display(label, options)\n",
    "display(submit_button, output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ailtk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
