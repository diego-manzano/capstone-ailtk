{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Case Study: Transform data for modeling using a data integration tool\n",
    "##### (GenAI Life Cycle Phase 3: Data Preparation self-assesment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2816208d5c48a08d9c6ddea5c3251a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(HTML(value='<h3 style=\\'color: #1e7e34; display: inline;\\'>PRE-READING: Solution of \"(2) Case St…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# EDA Pre-Reading Data Content\n",
    "eda_pre_reading_data = [\n",
    "    [\"<b>(2a) Perform Exploratory Data Analysis (EDA)</b>\", \n",
    "     (\"In your EDA, you are expected to get an overview of the categorical, ordinal, and interval variables present in the datasets \"\n",
    "      \"and identify how they may later be used for the Retrieval-Augmented Generation (RAG) of a virtual agent instance in this toolkit. \"\n",
    "      \"This dataset contains information on restaurants, including reviews, user ratings, and business details.<br>\"\n",
    "      \"<ul style='margin-left: 20px;'>\"\n",
    "      \"<li>Understand the data structure by analyzing key variables and their distributions.</li>\"\n",
    "      \"<li>Identify data types, such as categorical, ordinal, and interval variables.</li>\"\n",
    "      \"<li>Recognize potential use cases for RAG-based integration.</li>\"\n",
    "      \"</ul>\"\n",
    "      \"<b>NOTE:</b> The file you will be directed to below may take a few minutes to load given the size of the datasets used in this Case Study.<br>\"\n",
    "      \"<a href='case-files/ailtk-running-code-case-2.ipynb' target='_blank' style='color: #1e7e34; text-decoration: underline;'>\"\n",
    "      \"(Click here to open Solution: Case Study 2 in Visual Studio Code)</a><br>\"\n",
    "      \"<a href='case-files/solution-case-study-2.pdf' target='_blank' style='color: #1e7e34; text-decoration: underline;'>\"\n",
    "      \"(Alternative: PDF version)</a><br>\")\n",
    "    ],\n",
    "    \n",
    "    [\"<b>Schema Analysis:</b>\", \n",
    "     (\"<ul style='margin-left: 20px;'>\"\n",
    "      \"<li><b>yelp_academic_dataset_business.csv</b>: Contains business information.<br>\"\n",
    "      \"Key columns: <code>business_id</code>, <code>name</code>, <code>categories</code>, <code>stars</code>, <code>review_count</code>, etc.</li>\"\n",
    "      \"<li><b>yelp_academic_dataset_review.csv</b>: Contains reviews of businesses.<br>\"\n",
    "      \"Key columns: <code>review_id</code>, <code>user_id</code>, <code>business_id</code>, <code>stars</code>, <code>text</code>, <code>date</code>, etc.</li>\"\n",
    "      \"<li><b>yelp_academic_dataset_user.csv</b>: Contains user data.<br>\"\n",
    "      \"Key columns: <code>user_id</code>, <code>name</code>, <code>review_count</code>, <code>friends</code>, <code>yelping_since</code>, etc.</li>\"\n",
    "      \"</ul>\")],\n",
    "    \n",
    "    [\"<b>EDA Summary:</b>\", \n",
    "     (\"The data primarily consists of interval and categorical variables, with <b>'stars'</b> as an example of ordinal data. \"\n",
    "      \"These variables provide a basis for our upcoming data transformation.\"\n",
    "      \"<ul style='margin-left: 20px;'>\"\n",
    "      \"<li><b>Business Dataset</b>: Provides detailed information on businesses, including location, categories, and operational details. \"\n",
    "      \"Key for identifying review sources and geographical trends.</li>\"\n",
    "      \"<li><b>Review Dataset</b>: Links users to businesses via reviews. Essential for analyzing customer feedback and ratings.</li>\"\n",
    "      \"<li><b>User Dataset</b>: Captures user activity and social connections, valuable for understanding reviewer demographics and engagement.</li>\"\n",
    "      \"</ul>\")],\n",
    "\n",
    "    [\"<b>Data Relationships:</b>\", \n",
    "     (\"<ul style='margin-left: 20px;'>\"\n",
    "      \"<li><code>business_id</code>: Links <b>businesses</b> to <b>reviews</b>.</li>\"\n",
    "      \"<li><code>user_id</code>: Links <b>reviews</b> to <b>users</b>.</li>\"\n",
    "      \"</ul>\")]\n",
    "]\n",
    "\n",
    "# Create content for the widget\n",
    "eda_pre_reading_content = widgets.VBox([widgets.HTML(value=f\"{item[0]}<br>{item[1]}\") for item in eda_pre_reading_data])\n",
    "\n",
    "# Styled Box for EDA Pre-Reading\n",
    "styled_eda_box = widgets.Box(\n",
    "    [widgets.HTML(value=\"<h3 style='color: #1e7e34; display: inline;'>PRE-READING: Solution of \\\"(2) Case Study: Source and investigate usable data sources\\\" </h3>\"),\n",
    "     widgets.HTML(value=\"<hr style='border: 1px solid #1e7e34;'>\"),  # Horizontal line for separation\n",
    "     eda_pre_reading_content],\n",
    "    layout=widgets.Layout(\n",
    "        border=\"2px solid #1e7e34\",\n",
    "        padding=\"20px\",\n",
    "        width=\"90%\",\n",
    "        margin=\"20px 0px\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the styled box\n",
    "display(styled_eda_box)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Case Scenario:**\n",
    "\n",
    "> With your exploratory data analysis (EDA) from Activity 2 complete, Welp now requires the transformation of the analyzed data into a format suitable for the AI-powered virtual assistant. Management envisions a virtual agent capable of personalized **restaurant and bar** recommendations, and this step is crucial to ensure the data is usable for the virtual assistant’s recommendation engine.\n",
    ">\n",
    "> Your role as an AI developer is to process and structure the dataset in a way that it can be effectively utilized by the virtual assistant. This includes transforming the raw data from the dataset into a format that captures essential features such as restaurant names, cuisine types, user ratings, review highlights, ambiance descriptions, and other relevant data, while ensuring compatibility with the AI system's needs.\n",
    ">\n",
    "> The transformation process will require you to clean, filter, organize, merge, and label the datasets in a format that is later usable for Retrieval Augmented Generation (RAG) .\n",
    ">\n",
    "> Your tasks are as follows:\n",
    ">\n",
    "> (a) **Identify the file type and format (or shape) that the data will be transformed into.** The dataset format must compatible with machine learning models and can be easily accessed by the recommendation engine. Export the dataset into a file format suitable for training and real-time recommendation (e.g., CSV, Excel).\n",
    ">\n",
    "> (b) **Use Apache Hop to transform data into a shape and file type suitable for RAG**, ensuring that it is in a structured and consistent format. Handle any missing or incomplete information, normalize textual data, and prepare the dataset for AI consumption. \n",
    ">\n",
    "> By completing these tasks, you will gain hands-on experience in data preprocessing, cleaning, and structuring data for AI-based systems, preparing the dataset for deployment in a personalized recommendation system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre-requisites:\n",
    "- [Open Apache Hop](../ailtk_learning-management-module/learning-files/ailtk-apachehop-howto.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) **Identify the file type and format (or shape) that the data will be transformed into.** The dataset format must compatible with machine learning models and can be easily accessed by the recommendation engine. Export the dataset into a file format suitable for training and real-time recommendation (e.g., CSV, Excel).\n",
    "\n",
    "#### (b) **Use Apache Hop to transform data into a shape and file type suitable for RAG**, ensuring that it is in a structured and consistent format. Handle any missing or incomplete information, normalize textual data, and prepare the dataset for AI consumption.\n",
    "\n",
    "> SOLUTION:\n",
    ">\n",
    "> You can view a completed Pipeline and accomplished spreadsheet for this task here:\n",
    ">\n",
    "> <a href='case-files/ailtk-solutions-case-3.ipynb' target='_blank'>Opens the file manager</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer the following to proceed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e150fcc2175d42c4846f786e4f0ab5fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q1: How can data transformation enhance recommendation accuracy?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d372ea3752d14ed0ad78ce33686d933c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=('By ensuring consistent, relevant, and struct…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75fecdaf55d44f85b9f76a8253298480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q2: What are the challenges of integrating multiple data sources?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41462b35ea1244baa59a6f3bab1dc08f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=('Disparate formats, large sizes, and missing …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902915ccef624dc6a23b949b28870425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q3: How can the recommendation system leverage EDA (Exploratory Data Analysis) findings?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a3b7d7ecf745f9b5cd3f20964d89c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=('By providing insights like cuisine popularit…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1e3fb93748442e9bb7c04d496ebb4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q4: What tools or techniques will ensure scalability for large datasets?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f516622357a490080e6f597d533d51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=('Using chunking, parallel processing, and dat…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb5a41eae9a4cb5aaa08d1b30058b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q5: What must be done before merging datasets in Apache Hop?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f13c1c09296487093d3f785d77c4924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=(\"Datasets must be sorted using a 'Sort Rows' …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd33529410e437588888618272963f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Submit Answers', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8144bdb3204b03b3b8a355decd2c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Define questions and options\n",
    "questions = [\n",
    "    {\n",
    "        \"question\": \"How can data transformation enhance recommendation accuracy?\",\n",
    "        \"options\": [\n",
    "            \"By ensuring consistent, relevant, and structured inputs for the model to learn from\",\n",
    "            \"By reducing the volume of data available for analysis\",\n",
    "            \"By eliminating all inconsistencies in the dataset\",\n",
    "            \"By focusing solely on user demographics\"\n",
    "        ],\n",
    "        \"answer\": \"By ensuring consistent, relevant, and structured inputs for the model to learn from\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the challenges of integrating multiple data sources?\",\n",
    "        \"options\": [\n",
    "            \"Disparate formats, large sizes, and missing or inconsistent data\",\n",
    "            \"Having too few data sources\",\n",
    "            \"Maintaining the same file type across sources\",\n",
    "            \"Lack of variety in the data\"\n",
    "        ],\n",
    "        \"answer\": \"Disparate formats, large sizes, and missing or inconsistent data\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How can the recommendation system leverage EDA (Exploratory Data Analysis) findings?\",\n",
    "        \"options\": [\n",
    "            \"By providing insights like cuisine popularity, user sentiment trends, and ambiance preferences to refine filtering criteria\",\n",
    "            \"By eliminating irrelevant data points\",\n",
    "            \"By creating more data points from the existing ones\",\n",
    "            \"By using only the most recent user feedback\"\n",
    "        ],\n",
    "        \"answer\": \"By providing insights like cuisine popularity, user sentiment trends, and ambiance preferences to refine filtering criteria\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What tools or techniques will ensure scalability for large datasets?\",\n",
    "        \"options\": [\n",
    "            \"Using chunking, parallel processing, and database storage (e.g., SQLite or PostgreSQL)\",\n",
    "            \"Using a single-threaded process for data handling\",\n",
    "            \"Limiting the dataset size to 100 entries\",\n",
    "            \"Compressing the data to reduce storage requirements\"\n",
    "        ],\n",
    "        \"answer\": \"Using chunking, parallel processing, and database storage (e.g., SQLite or PostgreSQL)\"\n",
    "    },\n",
    "    {\n",
    "    \"question\": \"What must be done before merging datasets in Apache Hop?\",\n",
    "    \"options\": [\n",
    "        \"Datasets must be sorted using a 'Sort Rows' transform prior to two inputs being joined\",\n",
    "        \"Datasets must be formatted as CSV files before merging\",\n",
    "        \"All rows must be the same before merging\",\n",
    "        \"Nothing\"\n",
    "    ],\n",
    "    \"answer\": \"Datasets must be sorted using a 'Sort Rows' transform prior to two inputs being joined\"\n",
    "}\n",
    "\n",
    "]\n",
    "\n",
    "# Widgets for questions\n",
    "quiz_widgets = []\n",
    "for i, q in enumerate(questions):\n",
    "    question_label = widgets.Label(value=f\"Q{i+1}: {q['question']}\")\n",
    "    options = widgets.RadioButtons(\n",
    "        options=q['options'],\n",
    "        description='',\n",
    "        disabled=False,\n",
    "        value=None,\n",
    "        layout=widgets.Layout(width='90%', height='auto')  # Ensures proper layout for longer options\n",
    "    )\n",
    "    quiz_widgets.append((question_label, options))\n",
    "\n",
    "# Button to submit answers\n",
    "submit_button = widgets.Button(description=\"Submit Answers\", button_style=\"primary\")\n",
    "output = widgets.Output()\n",
    "\n",
    "# Flag to track if the error message is already displayed\n",
    "error_displayed = False\n",
    "\n",
    "# Define button click event\n",
    "def on_submit_click(b):\n",
    "    global error_displayed\n",
    "    # Disable the submit button\n",
    "    submit_button.disabled = True\n",
    "    clear_output(wait=True)\n",
    "    unanswered = False\n",
    "    score = 0\n",
    "\n",
    "    # Check if all questions are answered\n",
    "    for i, (label, options) in enumerate(quiz_widgets):\n",
    "        if options.value is None:  # If a question is left unanswered\n",
    "            unanswered = True\n",
    "\n",
    "    with output:\n",
    "        if unanswered:\n",
    "            if not error_displayed:  # Only display the error if it hasn't been shown already\n",
    "                error_displayed = True\n",
    "                # Display error message in red\n",
    "                display(widgets.HTML(\n",
    "                    '<p style=\"color: red; font-weight: bold;\">Please answer all the questions before submitting.</p>'\n",
    "                ))\n",
    "            submit_button.disabled = False  # Re-enable button if there's an error\n",
    "        else:\n",
    "            error_displayed = False  # Reset the flag if all questions are answered\n",
    "            submit_button.button_style = \"\"  # Reset button style to default after click\n",
    "            # Calculate score\n",
    "            for i, (label, options) in enumerate(quiz_widgets):\n",
    "                user_answer = options.value\n",
    "                correct_answer = questions[i][\"answer\"]\n",
    "                if user_answer == correct_answer:\n",
    "                    score += 1\n",
    "                print(f\"Q{i+1}: {questions[i]['question']}\")\n",
    "                print(f\"  - Your answer: {user_answer}\")\n",
    "                print(f\"  - Correct answer: {correct_answer}\")\n",
    "                print()\n",
    "\n",
    "            print(f\"You scored {score}/{len(questions)}! ({(score / len(questions)) * 100:.2f}%)\")\n",
    "            \n",
    "            # Show Continue or Try Again button based on score\n",
    "            if score >= 0.8 * len(questions):\n",
    "                continue_button = widgets.HTML(\n",
    "                    '<a href=\"case-study-4.ipynb\" style=\"display: inline-block; padding: 10px 15px; '\n",
    "                    'background-color: #28a745; color: white; text-decoration: none; border-radius: 5px;\">'\n",
    "                    'Continue</a>'\n",
    "                )\n",
    "                display(continue_button)\n",
    "            else:\n",
    "                try_again_button = widgets.HTML(\n",
    "                    '<a href=\"case-study-3.ipynb\" style=\"display: inline-block; padding: 10px 15px; '\n",
    "                    'background-color: #dc3545; color: white; text-decoration: none; border-radius: 5px;\">'\n",
    "                    'Score at least 80% to continue. Try Again</a>'\n",
    "                )\n",
    "                display(try_again_button)\n",
    "\n",
    "# Attach event to the submit button\n",
    "submit_button.on_click(on_submit_click)\n",
    "\n",
    "# Display the quiz\n",
    "for label, options in quiz_widgets:\n",
    "    display(label, options)\n",
    "display(submit_button, output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ailtk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
