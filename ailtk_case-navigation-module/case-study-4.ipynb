{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Case Study: Accessing cloud-based LLM models and implementing RAG\n",
    "##### (GenAI Life Cycle Phase 4: Development self-assesment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: output of transform (open file manager for them)\n",
    "\n",
    "// ailtk_case-navigation-module/case-files/ailtk-solutions-case3.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case Scenario\n",
    ">\n",
    "> With the dataset fully prepared and transformed for the AI-powered virtual assistant, the next step involves integrating cloud-based Large Language Models (LLMs) to implement a Retrieval-Augmented Generation (RAG) approach. This phase is crucial in ensuring that the virtual assistant can generate highly relevant, personalized restaurant recommendations by leveraging powerful language models in the cloud.\n",
    ">\n",
    "> As an AI developer, your role is to integrate the cloud-based LLMs into the virtual assistant's architecture, and implement RAG to improve the assistant’s recommendation capabilities. RAG allows the assistant to access external sources of information and combine them with the language model’s abilities to generate context-aware and tailored restaurant suggestions. In this step, you will need to ensure that the assistant not only provides the best restaurant recommendations based on the user’s input but also offers insightful explanations and justifications for those recommendations.\n",
    ">\n",
    "> The tasks will involve:\n",
    "> \n",
    "> (a) **Integrate cloud-based LLMs** into the virtual assistant’s architecture, ensuring compatibility with the dataset and the assistant’s functionalities.  \n",
    "> Ensure that the system is able to seamlessly access and interact with the cloud-based LLM models for efficient processing of user input.\n",
    ">\n",
    "> (b) **Implement a Retrieval-Augmented Generation (RAG) pipeline**, ensuring that relevant information is retrieved from the dataset and passed to the LLM to generate personalized recommendations.  \n",
    "> Leverage the power of RAG to pull contextual data from the dataset, such as restaurant reviews, cuisine types, and user preferences, to provide highly relevant suggestions to the user.\n",
    ">\n",
    "> (c) **Evaluate the model’s performance**, adjusting the process to fine-tune the responses and ensuring that the virtual assistant provides accurate, personalized, and relevant restaurant suggestions.  \n",
    "> Monitor how well the assistant handles a variety of user inputs and continuously improve its ability to generate meaningful recommendations based on data retrieved from the restaurant dataset.\n",
    ">\n",
    "> By completing these tasks, you will gain hands-on experience on developing virtual agents by implementing cloud-based LLMs, integrating RAG into AI systems, and improving recommendation accuracy by utilizing external data sources in real-time. This phase will bring you closer to developing a fully functioning AI-powered virtual assistant for restaurant recommendations, helping customers make better dining decisions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer the following\n",
    "(TIP: Try using your newly developed virtual agent to answer some of the questions below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Define questions and options\n",
    "questions = [\n",
    "    {\n",
    "        \"question\": \"SAMPLE QUESTION ONLY: What is the main problem that the virtual assistant for Welp is trying to solve?\",\n",
    "        \"options\": [\n",
    "            \"Difficulty in finding trustworthy reviews for restaurants.\",\n",
    "            \"Decision fatigue caused by too many dining options and lack of personalized filtering.\",\n",
    "            \"Lack of information about restaurant locations.\",\n",
    "            \"Inconsistent pricing across restaurants.\"\n",
    "        ],\n",
    "        \"answer\": \"Decision fatigue caused by too many dining options and lack of personalized filtering.\"\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "# Widgets for questions\n",
    "quiz_widgets = []\n",
    "for i, q in enumerate(questions):\n",
    "    question_label = widgets.Label(value=f\"Q{i+1}: {q['question']}\")\n",
    "    options = widgets.RadioButtons(\n",
    "        options=q['options'],\n",
    "        description='',\n",
    "        disabled=False,\n",
    "        value=None,\n",
    "        layout=widgets.Layout(width='90%', height='auto')  # Ensures proper layout for longer options\n",
    "    )\n",
    "    quiz_widgets.append((question_label, options))\n",
    "\n",
    "# Button to submit answers\n",
    "submit_button = widgets.Button(description=\"Submit Answers\", button_style=\"primary\")\n",
    "output = widgets.Output()\n",
    "\n",
    "# Flag to track if the error message is already displayed\n",
    "error_displayed = False\n",
    "\n",
    "# Define button click event\n",
    "def on_submit_click(b):\n",
    "    global error_displayed\n",
    "    # Disable the submit button\n",
    "    submit_button.disabled = True\n",
    "    clear_output(wait=True)\n",
    "    unanswered = False\n",
    "    score = 0\n",
    "\n",
    "    # Check if all questions are answered\n",
    "    for i, (label, options) in enumerate(quiz_widgets):\n",
    "        if options.value is None:  # If a question is left unanswered\n",
    "            unanswered = True\n",
    "\n",
    "    with output:\n",
    "        if unanswered:\n",
    "            if not error_displayed:  # Only display the error if it hasn't been shown already\n",
    "                error_displayed = True\n",
    "                # Display error message in red\n",
    "                display(widgets.HTML(\n",
    "                    '<p style=\"color: red; font-weight: bold;\">Please answer all the questions before submitting.</p>'\n",
    "                ))\n",
    "            submit_button.disabled = False  # Re-enable button if there's an error\n",
    "        else:\n",
    "            error_displayed = False  # Reset the flag if all questions are answered\n",
    "            submit_button.button_style = \"\"  # Reset button style to default after click\n",
    "            # Calculate score\n",
    "            for i, (label, options) in enumerate(quiz_widgets):\n",
    "                user_answer = options.value\n",
    "                correct_answer = questions[i][\"answer\"]\n",
    "                if user_answer == correct_answer:\n",
    "                    score += 1\n",
    "                print(f\"Q{i+1}: {questions[i]['question']}\")\n",
    "                print(f\"  - Your answer: {user_answer}\")\n",
    "                print(f\"  - Correct answer: {correct_answer}\")\n",
    "                print()\n",
    "\n",
    "            print(f\"You scored {score}/{len(questions)}! ({(score / len(questions)) * 100:.2f}%)\")\n",
    "            \n",
    "            # Show Continue or Try Again button based on score\n",
    "            if score >= 0.8 * len(questions):\n",
    "                continue_button = widgets.HTML(\n",
    "                    '<a href=\"case-study-4.ipynb\" style=\"display: inline-block; padding: 10px 15px; '\n",
    "                    'background-color: #28a745; color: white; text-decoration: none; border-radius: 5px;\">'\n",
    "                    'Continue</a>'\n",
    "                )\n",
    "                display(continue_button)\n",
    "            else:\n",
    "                try_again_button = widgets.HTML(\n",
    "                    '<a href=\"case-study-3.ipynb\" style=\"display: inline-block; padding: 10px 15px; '\n",
    "                    'background-color: #dc3545; color: white; text-decoration: none; border-radius: 5px;\">'\n",
    "                    'Score at least 80% to continue. Try Again</a>'\n",
    "                )\n",
    "                display(try_again_button)\n",
    "\n",
    "# Attach event to the submit button\n",
    "submit_button.on_click(on_submit_click)\n",
    "\n",
    "# Display the quiz\n",
    "for label, options in quiz_widgets:\n",
    "    display(label, options)\n",
    "display(submit_button, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Next: Case Study 5](../ltk_case-study/case-study-5.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
