{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Case Study: Accessing cloud-based LLM models and implementing RAG\n",
    "##### (GenAI Life Cycle Phase 4: Development self-assesment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "404794c900e845298ded2d4685adc405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(HTML(value='<h3 style=\\'color: #1e7e34; display: inline;\\'>PRE-READING: Solution of \"(3) Case St…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Transform Data Pre-Reading Data Content\n",
    "transform_data_pre_reading_data = [\n",
    "    [\"<b>(3a) Identify File Type and Format</b>\", \n",
    "     (\"The dataset format must be compatible with the large language model (LLM) API (Google Gemini in our case). \"\n",
    "      \"For example, export the dataset into spreadsheet file formats such as CSV or Excel to ensure usability for training and real-time recommendation tasks.<br>\")],\n",
    "    \n",
    "    [\"<b>(3b) Use Apache Hop for Data Transformation:</b>\", \n",
    "     (\"Utilize Apache Hop to transform data into a structured and consistent format suitable for Retrieval-Augmented Generation (RAG).<br><br>\"\n",
    "      \"You can view a completed Pipeline and accomplished spreadsheet for this task here: \"\n",
    "      \"<a href='case-files/ailtk-solutions-case-3.ipynb' target='_blank' style='color: #1e7e34; text-decoration: underline;'>Opens the file manager</a>\")],\n",
    "]\n",
    "\n",
    "# Create content for the widget\n",
    "transform_data_pre_reading_content = widgets.VBox([widgets.HTML(value=f\"{item[0]}<br>{item[1]}\") for item in transform_data_pre_reading_data])\n",
    "\n",
    "# Styled Box for Transform Data Pre-Reading\n",
    "styled_transform_data_box = widgets.Box(\n",
    "    [widgets.HTML(value=\"<h3 style='color: #1e7e34; display: inline;'>PRE-READING: Solution of \\\"(3) Case Study: Transform data for modeling using a data integration tool\\\"</h3>\"),\n",
    "     widgets.HTML(value=\"<hr style='border: 1px solid #1e7e34;'>\"),  # Horizontal line for separation\n",
    "     transform_data_pre_reading_content],\n",
    "    layout=widgets.Layout(\n",
    "        border=\"2px solid #1e7e34\",\n",
    "        padding=\"20px\",\n",
    "        width=\"90%\",\n",
    "        margin=\"20px 0px\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the styled box\n",
    "display(styled_transform_data_box)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case Scenario\n",
    ">\n",
    "> With the dataset fully prepared and transformed for the AI-powered virtual assistant, the next step involves integrating cloud-based Large Language Models (LLMs) to implement a Retrieval-Augmented Generation (RAG) approach. This phase is crucial in ensuring that the virtual assistant can generate highly relevant, personalized restaurant recommendations by leveraging powerful language models in the cloud.\n",
    ">\n",
    "> As an AI developer, your role is to integrate the cloud-based LLMs into the virtual assistant's architecture, and implement RAG to improve the assistant’s recommendation capabilities. RAG allows the assistant to access external sources of information and combine them with the language model’s abilities to generate context-aware and tailored restaurant suggestions. In this step, you will need to ensure that the assistant not only provides the best restaurant recommendations based on the user’s input but also offers insightful explanations and justifications for those recommendations.\n",
    ">\n",
    "> The tasks will involve:\n",
    "> \n",
    "> (a) **Design and refine prompts in Google AI Studio** to ensure the Gemini model understands user intents clearly and provides accurate responses.\n",
    ">\n",
    "> (b) **Obtain and configure the API key** to connect the Google Gemini model with your system. NOTE: You will be able to reuse your API key from Practice Learning Activity 4 for the sake of this case.\n",
    ">\n",
    "> (c) **Apply Retrieval-Augmented Generation (RAG)** techniques to integrate the LLM model with\n",
    ">\n",
    "> By completing these tasks, you will gain hands-on experience on developing virtual agents by implementing cloud-based LLMs, integrating RAG into AI systems, and improving recommendation accuracy by utilizing external data sources in real-time. This phase will bring you closer to developing a fully functioning AI-powered virtual assistant for restaurant recommendations, helping customers make better dining decisions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-requisite:\n",
    "- Create a Jupyter Notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the tasks as follows:\n",
    "\n",
    "\n",
    "#### (a) **Design and refine prompts in Google AI Studio** to ensure the Gemini model understands user intents clearly and provides accurate responses.\n",
    "\n",
    "#### (b) **Obtain and configure the API key** to connect the Google Gemini model with your system. NOTE: You will be able to reuse your API key from Practice Learning Activity 4 for the sake of this case.\n",
    "\n",
    "#### (c) **Apply Retrieval-Augmented Generation (RAG)** techniques to integrate the LLM model with\n",
    "\n",
    "> ##### SOLUTION :\n",
    ">> <a href='case-files/ailtk-running-code-case-4.ipynb' target='_blank'>Click here to open Solution: Case Study 4 in Visual Studio Code</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may reference this checklist to self-check your output for this Case Study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05cf45a358f4b09871381e4f70382fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, layout=Layout(width='auto')), Label(value='(3a) Identify File Type and Fo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea40c9596c643c9b389dece0abf64ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, layout=Layout(width='auto')), Label(value='(3a) Identify File Type and Fo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af60a10982a14422a99cd71f8e0682ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, layout=Layout(width='auto')), Label(value='(3b) Use Apache Hop for Data T…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a43111140b794bdbb876a29fe3cd7b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, layout=Layout(width='auto')), Label(value='(3b) Use Apache Hop for Data T…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d3208ab4264707a1911e12335c0a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, layout=Layout(width='auto')), Label(value='(3b) Use Apache Hop for Data T…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6436f1610be9404796c3ad5b9b72b1c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "## Define checklist items based on key learning points\n",
    "checklist_items = [\n",
    "    \"(4a) Prompt Engineering in Google AI Studio: Have you designed and refined a prompt in Google AI Studio to ensure the Gemini model accurately interprets user intents?\",\n",
    "    \"(4a) Prompt Engineering in Google AI Studio: Did you include key elements in the system instruction, such as understanding user intent, leveraging preferences, and handling ambiguous queries?\",\n",
    "    \"(4a) Prompt Engineering in Google AI Studio: Have you tested the model’s response quality using different prompts and user inputs?\",\n",
    "\n",
    "    \"(4b) API Integration: Have you correctly configured the Gemini API key and integrated it into your system?\",\n",
    "    \"(4b) API Integration: Did you reuse the API key from Practice Learning Activity 4 for this case?\",\n",
    "    \"(4b) API Integration: Have you tested the API calls to confirm they return expected responses?\",\n",
    "\n",
    "    \"(4c) Data Utilization with RAG: Have you applied Retrieval-Augmented Generation (RAG) techniques to enhance responses with curated datasets?\",\n",
    "    \"(4c) Data Utilization with RAG: Did you preprocess and structure data (e.g., CSV or Excel) for integration into the RAG pipeline?\",\n",
    "    \"(4c) Data Utilization with RAG: Have you implemented and validated the RAG pipeline, including corpus storage and retrieval mechanisms?\",\n",
    "    \"(4c) Data Utilization with RAG: Did you test the augmented response generation using a combination of model inference and retrieved data?\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create checklist widgets with wrapping enabled\n",
    "checkboxes = [widgets.Checkbox(value=False, description=\"\", layout=widgets.Layout(width='auto')) for _ in checklist_items]\n",
    "labels = [widgets.Label(value=item) for item in checklist_items]\n",
    "\n",
    "# Output widget for completion message\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to check if all items are marked\n",
    "def check_completion(change):\n",
    "    if all(cb.value for cb in checkboxes):  # If all checkboxes are checked\n",
    "        with output:\n",
    "            clear_output()\n",
    "            display(HTML('<p style=\"color: green; font-weight: bold;\">✅ You have successfully covered all key points!</p>'))\n",
    "    else:\n",
    "        with output:\n",
    "            clear_output()\n",
    "\n",
    "# Attach event listeners to checkboxes\n",
    "for cb in checkboxes:\n",
    "    cb.observe(check_completion, 'value')\n",
    "\n",
    "# Display checklist with labels for proper text wrapping\n",
    "checklist_ui = [widgets.HBox([cb, label]) for cb, label in zip(checkboxes, labels)]\n",
    "display(*checklist_ui, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer the following to proceed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5072f1823cd54ccfac7d57d9f11d5fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q1: What is the primary goal of prompt engineering when working with large language models?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b1ebb5cb1f7410d8658baddc4d4715b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=('To provide clear and context-aware instructi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2f71f81d34247d8bd688282af3fac7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q2: What must be done before you can use the API in Google AI Studio?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ab7a1f44554fb69db698b3ba8bfaea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=('Create an API key', 'Install additional libr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8a00bb272f465f82cda1930f3791af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q3: Which of the following steps is necessary after obtaining your API key in Google AI Studio?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a74a881d11b4fe4bed9f5f2dae7aa9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=('Copy the key to your clipboard and store it …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434ea5303d354fdd8371d76ea9868449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value=\"Q4: What is the purpose of the 'System Instructions' section in Google AI Studio?\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a79d686817647529646461f5d1218be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=(\"To specify the tone and style of the LLM's r…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "361913842152437582460345cc3cae9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q5: Which transform must be applied to datasets in Apache Hop before merging them?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4bbe8d1691d42c19be49470da863adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=('Sort Rows transform', 'Filter Rows transform…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc028c414b424918a38e2c5ad6c3532d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q6: How can prompt engineering improve the functionality of a virtual agent?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e46c6517a064a04ab7c7a3166bd957b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=(\"By providing clear, context-aware instructio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a0d48b98e6f4f008b4cf35a47effc33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q7: What technique is crucial for combining large-language models (LLMs) with specific knowledge?…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65659808d3345279cb17f53a43800db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=('Retrieval-Augmented Generation (RAG)', 'Data…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563f9223183f450f86374de2c442eced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q8: What is the purpose of the `jaccard_similarity` function in the RAG implementation?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef1567941734870ba867390242ff7a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=('To calculate the similarity between user inp…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f350221114457ba7caf41a822bb796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q9: What does the model do after receiving the augmented input in RAG?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79e5518af594d61868248261a84d41d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=('Generates contextually relevant responses us…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a524f649b67a481fbca8d5a89cab71ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Q10: True or False: The Jaccard similarity is the only way to find similar documents in Retrieval…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c609d700ac41b6bcee3d8a03798d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(layout=Layout(height='auto', width='90%'), options=('True', 'False'), value=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea31a344968468da99e995d6bb4587e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Submit Answers', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b0a1c755bf4cbdbd50462a831c7284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Define questions and options\n",
    "questions = [\n",
    "    {\n",
    "        \"question\": \"What is the primary goal of prompt engineering when working with large language models?\",\n",
    "        \"options\": [\n",
    "            \"To provide clear and context-aware instructions to the model\",\n",
    "            \"To optimize the performance of the model on large datasets\",\n",
    "            \"To ensure the model can generate code automatically\",\n",
    "            \"To design a user interface for the model\"\n",
    "        ],\n",
    "        \"answer\": \"To provide clear and context-aware instructions to the model\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What must be done before you can use the API in Google AI Studio?\",\n",
    "        \"options\": [\n",
    "            \"Create an API key\",\n",
    "            \"Install additional libraries\",\n",
    "            \"Set up a payment method\",\n",
    "            \"Activate a subscription plan\"\n",
    "        ],\n",
    "        \"answer\": \"Create an API key\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which of the following steps is necessary after obtaining your API key in Google AI Studio?\",\n",
    "        \"options\": [\n",
    "            \"Copy the key to your clipboard and store it securely\",\n",
    "            \"Use it immediately in your code without saving\",\n",
    "            \"Share it with the public for collaboration\",\n",
    "            \"Send it to Google support\"\n",
    "        ],\n",
    "        \"answer\": \"Copy the key to your clipboard and store it securely\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the purpose of the 'System Instructions' section in Google AI Studio?\",\n",
    "        \"options\": [\n",
    "            \"To specify the tone and style of the LLM's responses\",\n",
    "            \"To input API keys for integration\",\n",
    "            \"To set up project permissions\",\n",
    "            \"To upload datasets\"\n",
    "        ],\n",
    "        \"answer\": \"To specify the tone and style of the LLM's responses\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which transform must be applied to datasets in Apache Hop before merging them?\",\n",
    "        \"options\": [\n",
    "            \"Sort Rows transform\",\n",
    "            \"Filter Rows transform\",\n",
    "            \"Merge Rows transform\",\n",
    "            \"Group By transform\"\n",
    "        ],\n",
    "        \"answer\": \"Sort Rows transform\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How can prompt engineering improve the functionality of a virtual agent?\",\n",
    "        \"options\": [\n",
    "            \"By providing clear, context-aware instructions that guide the model's behavior\",\n",
    "            \"By storing large datasets for quick retrieval\",\n",
    "            \"By reducing the need for API integration\",\n",
    "            \"By increasing the computational power of the AI\"\n",
    "        ],\n",
    "        \"answer\": \"By providing clear, context-aware instructions that guide the model's behavior\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What technique is crucial for combining large-language models (LLMs) with specific knowledge?\",\n",
    "        \"options\": [\n",
    "            \"Retrieval-Augmented Generation (RAG)\",\n",
    "            \"Data Normalization\",\n",
    "            \"Neural Networks\",\n",
    "            \"Batch Processing\"\n",
    "        ],\n",
    "        \"answer\": \"Retrieval-Augmented Generation (RAG)\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the purpose of the `jaccard_similarity` function in the RAG implementation?\",\n",
    "        \"options\": [\n",
    "            \"To calculate the similarity between user input and the documents in the corpus\",\n",
    "            \"To clean the data before processing\",\n",
    "            \"To format the user query for the model\",\n",
    "            \"To extract features from the dataset\"\n",
    "        ],\n",
    "        \"answer\": \"To calculate the similarity between user input and the documents in the corpus\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What does the model do after receiving the augmented input in RAG?\",\n",
    "        \"options\": [\n",
    "            \"Generates contextually relevant responses using the retrieved data\",\n",
    "            \"Filters out irrelevant documents\",\n",
    "            \"Sorts the documents for better accuracy\",\n",
    "            \"Stores the input for future use\"\n",
    "        ],\n",
    "        \"answer\": \"Generates contextually relevant responses using the retrieved data\"\n",
    "    },\n",
    "    {\n",
    "    \"question\": \"True or False: The Jaccard similarity is the only way to find similar documents in Retrieval-Augmented Generation (RAG).\",\n",
    "    \"options\": [\n",
    "        \"True\",\n",
    "        \"False\"\n",
    "    ],\n",
    "    \"answer\": \"False\"\n",
    "}\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Widgets for questions\n",
    "quiz_widgets = []\n",
    "for i, q in enumerate(questions):\n",
    "    question_label = widgets.Label(value=f\"Q{i+1}: {q['question']}\")\n",
    "    options = widgets.RadioButtons(\n",
    "        options=q['options'],\n",
    "        description='',\n",
    "        disabled=False,\n",
    "        value=None,\n",
    "        layout=widgets.Layout(width='90%', height='auto')  # Ensures proper layout for longer options\n",
    "    )\n",
    "    quiz_widgets.append((question_label, options))\n",
    "\n",
    "# Button to submit answers\n",
    "submit_button = widgets.Button(description=\"Submit Answers\", button_style=\"primary\")\n",
    "output = widgets.Output()\n",
    "\n",
    "# Flag to track if the error message is already displayed\n",
    "error_displayed = False\n",
    "\n",
    "# Define button click event\n",
    "def on_submit_click(b):\n",
    "    global error_displayed\n",
    "    # Disable the submit button\n",
    "    submit_button.disabled = True\n",
    "    clear_output(wait=True)\n",
    "    unanswered = False\n",
    "    score = 0\n",
    "\n",
    "    # Check if all questions are answered\n",
    "    for i, (label, options) in enumerate(quiz_widgets):\n",
    "        if options.value is None:  # If a question is left unanswered\n",
    "            unanswered = True\n",
    "\n",
    "    with output:\n",
    "        if unanswered:\n",
    "            if not error_displayed:  # Only display the error if it hasn't been shown already\n",
    "                error_displayed = True\n",
    "                # Display error message in red\n",
    "                display(widgets.HTML(\n",
    "                    '<p style=\"color: red; font-weight: bold;\">Please answer all the questions before submitting.</p>'\n",
    "                ))\n",
    "            submit_button.disabled = False  # Re-enable button if there's an error\n",
    "        else:\n",
    "            error_displayed = False  # Reset the flag if all questions are answered\n",
    "            submit_button.button_style = \"\"  # Reset button style to default after click\n",
    "            # Calculate score\n",
    "            for i, (label, options) in enumerate(quiz_widgets):\n",
    "                user_answer = options.value\n",
    "                correct_answer = questions[i][\"answer\"]\n",
    "                if user_answer == correct_answer:\n",
    "                    score += 1\n",
    "                print(f\"Q{i+1}: {questions[i]['question']}\")\n",
    "                print(f\"  - Your answer: {user_answer}\")\n",
    "                print(f\"  - Correct answer: {correct_answer}\")\n",
    "                print()\n",
    "\n",
    "            print(f\"You scored {score}/{len(questions)}! ({(score / len(questions)) * 100:.2f}%)\")\n",
    "            \n",
    "            # Show Continue or Try Again button based on score\n",
    "            if score >= 0.8 * len(questions):\n",
    "                continue_button = widgets.HTML(\n",
    "                    '<a href=\"case-study-5.ipynb\" style=\"display: inline-block; padding: 10px 15px; '\n",
    "                    'background-color: #28a745; color: white; text-decoration: none; border-radius: 5px;\">'\n",
    "                    'Continue</a>'\n",
    "                )\n",
    "                display(continue_button)\n",
    "            else:\n",
    "                try_again_button = widgets.HTML(\n",
    "                    '<a href=\"case-study-4.ipynb\" style=\"display: inline-block; padding: 10px 15px; '\n",
    "                    'background-color: #dc3545; color: white; text-decoration: none; border-radius: 5px;\">'\n",
    "                    'Score at least 80% to continue. Try Again</a>'\n",
    "                )\n",
    "                display(try_again_button)\n",
    "\n",
    "# Attach event to the submit button\n",
    "submit_button.on_click(on_submit_click)\n",
    "\n",
    "# Display the quiz\n",
    "for label, options in quiz_widgets:\n",
    "    display(label, options)\n",
    "display(submit_button, output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ailtk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
