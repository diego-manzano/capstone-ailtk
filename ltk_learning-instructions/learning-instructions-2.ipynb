{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Source and investigate usable data sources "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links to read:\n",
    "\n",
    "[1] \n",
    "\n",
    "[2] \n",
    "\n",
    "[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sourcing and investigating usable data sources is crucial. This involves identifying relevant data that can fine-tune the LLM to ensure the agent’s responses and recommendations have accurate and comprehensive information to interact with users effectively. By evaluating and selecting the right data sources, developers can enhance the virtual agent’s performance, making it more reliable and relevant in addressing user queries and providing tailored assistance.\n",
    "\n",
    "In the world of AI, data is the fuel that powers your models. The quality and quantity of your data directly impact the accuracy and performance of your AI applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (2A) Identifying Relevant Sources\n",
    "- Research existing data sources: Explore publicly available datasets, academic repositories, industry-specific databases, and other potential sources.\n",
    "- Consider data availability and accessibility: Evaluate whether the identified data sources are accessible and if there are any restrictions or costs associated with obtaining the data.\n",
    "- Leverage internal data: Utilize existing company knowledge bases, records, and other internal data sources to supplement external data.\n",
    "- Consider data ethics and privacy: Ensure that data acquisition and use comply with relevant ethical guidelines and privacy regulations.\n",
    "- Understanding Common Data Storage Formats for Existing Datasets\n",
    "    When searching for and utilizing existing datasets, you'll encounter them in various storage formats. Data Storage Formats fall into two general categories: Structured Data Formats and Unstructured Data Formats:\n",
    "    - Structured Data Formats\n",
    "        - SQL Databases: These are widely used for storing structured data with defined fields and relationships. They are ideal for relational data, such as customer information, sales data, and inventory records.\n",
    "        - CSV (Comma-Separated Values): A simple text format where values are separated by commas. CSV files are often used for exporting data from spreadsheets or databases.\n",
    "        - JSON (JavaScript Object Notation): A human-readable data format that stores data in key-value pairs. JSON is commonly used for representing structured data in APIs and web applications.\n",
    "    - Unstructured Data Formats\n",
    "        - Text Files: Plain text files can store various types of data, including documents, code, and log files.\n",
    "        - PDF (Portable Document Format): A file format used to represent documents, including text, images, and graphics.\n",
    "        - XML (Extensible Markup Language): A markup language for storing and transporting data. XML is often used for structured data, but it can also store unstructured content.\n",
    "        - Images: Formats like JPEG, PNG, and GIF are used for storing images.\n",
    "        - Audio and Video: Formats like MP3, WAV, MP4, and AVI are used for storing audio and video files.\n",
    "\n",
    "##### (2B) Evaluating Data Quality #Check google's guidelines about this\n",
    "Once you've identified relevant data sources, it's crucial to evaluate their quality. This ensures that the data you're using is accurate, reliable, and suitable for training your virtual agent. Here are the key factors to consider:\n",
    "- Accuracy: Verify the data's accuracy and reliability. This might involve checking sources, comparing with other data, or using data validation techniques.\n",
    "- Completeness: Ensure the data is comprehensive and doesn't have significant gaps. Identify missing values and consider imputation methods if necessary.\n",
    "- Consistency: Check for consistency in data formats and definitions. Standardize data if needed to ensure uniformity.\n",
    "- Timeliness: Consider the age of the data. Outdated data may not be relevant for training your virtual agent.\n",
    "Bias: Be aware of potential biases in the data and take steps to mitigate them. Analyze the data distribution and consider the data collection methods to identify potential biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data often comes in a messy, raw form that isn't ready to be used directly in building your AI model. Think of it like trying to cook a meal with ingredients that are still in their packaging and haven't been prepared. You need to open the packages, measure the ingredients, and mix them together before you can start cooking.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:\n",
    "\n",
    "\n",
    "*Show how to do it with tools*\n",
    "- Give files and/or code blocks when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-requsites: Ensure Anaconda and MySQL are running. Use the correct conda environment to run the code cells\n",
    "\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of the dataset and it being kinda messy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Data usually (if not always) needs to be transformed one way or a nother it to make it usable for a specific use case. This means changing its shape, format, or content to match the requirements of your model. For example, you might need to convert text data into numerical values, fill in missing data, or combine data from different sources.\n",
    "\n",
    "We'll discuss data transformation as a part of the next Learning Outcome (Transform data for modeling using a data integration tool) but first, our data needs to be investigated through a process called **data exploration**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2C) Data Exploration\n",
    "\n",
    " Data exploration is the process of examining data to understand its characteristics, identify patterns, and uncover potential issues before further analysis or modeling. It's like getting to know a new dataset before working with it.   \n",
    "\n",
    "Key techniques in data exploration include:\n",
    "Data visualization: Creating visual representations of the data to identify trends, outliers, and relationships. This can be done using charts, graphs, and other visualization tools.   \n",
    "Summary statistics: Calculating basic statistics like mean, median, mode, and standard deviation to understand data distribution.   \n",
    "Data profiling: Analyzing data attributes to identify data types, missing values, and data quality issues.   \n",
    "Correlation analysis: Examining relationships between different variables to identify potential dependencies.   \n",
    "\n",
    "Why is data exploration important?\n",
    "Understanding the data: Data exploration helps you gain a deeper understanding of the data, including its strengths, weaknesses, and potential limitations.   \n",
    "Identifying data quality issues: By exploring the data, you can identify and address issues such as missing values, outliers, and inconsistencies.   \n",
    "Informing data transformation: The insights gained from data exploration can guide your data transformation decisions, ensuring that the data is prepared effectively for modeling.\n",
    "Developing hypotheses: Data exploration can help you generate hypotheses about the data that can be tested through further analysis.   \n",
    "In essence, data exploration is a crucial step in the data analysis process that lays the foundation for more advanced techniques and insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice Learning\n",
    "\n",
    "Try answering [Practice Learning Activity 2](../ltk_learning-instructions-files/) yourself here before proceeding below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// Answer to Practice learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// Outro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Next: Case Study 2](../ltk_case-study/case-study-2.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_ltk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
